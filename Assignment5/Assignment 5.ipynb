{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 5.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"15CHi50nL1ZZhJd0PVPNJcmXR1UvSyQ3v","authorship_tag":"ABX9TyMBIyPje3p9OLWWnt8zL++U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"236fc4c4277e40798cf49671c852a91c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_36f79770e709432fac5f03de1a0c0268","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f7012411d3d04ec9947315fa7324a78c","IPY_MODEL_356a0e6a81404409ba12b4482a1280ed"]}},"36f79770e709432fac5f03de1a0c0268":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7012411d3d04ec9947315fa7324a78c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b4396577c938427ea4697f02d9931d59","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_552a056c286f4a3f867d9c7184641142"}},"356a0e6a81404409ba12b4482a1280ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0d30b336d7947e9b18b80da93e87a6d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 88133349.03it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0f2f57d2e634f1495af3814f4149e79"}},"b4396577c938427ea4697f02d9931d59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"552a056c286f4a3f867d9c7184641142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0d30b336d7947e9b18b80da93e87a6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f0f2f57d2e634f1495af3814f4149e79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"uzvV8KpDBBgC","executionInfo":{"status":"ok","timestamp":1605566680471,"user_tz":420,"elapsed":983,"user":{"displayName":"菅泳钦","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisNkEPQ1MIyihCSP3C7W28PHOGAXAyhKjVek8T=s64","userId":"04446447163478496729"}},"outputId":"ff620f1e-fd91-4e9d-f1bc-700fb826e020","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BfZvwvuzMwiO","executionInfo":{"status":"ok","timestamp":1605566683034,"user_tz":420,"elapsed":606,"user":{"displayName":"菅泳钦","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisNkEPQ1MIyihCSP3C7W28PHOGAXAyhKjVek8T=s64","userId":"04446447163478496729"}},"outputId":"6180779f-95c2-49d8-a80e-4d688e098afa","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd  \"drive/My Drive/Cmput 328/Assignment5\""],"execution_count":9,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive/Cmput 328/Assignment5'\n","/content/drive/My Drive/Cmput 328/Assignment5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8C24iMumNeDc","executionInfo":{"status":"ok","timestamp":1605566691373,"user_tz":420,"elapsed":471,"user":{"displayName":"菅泳钦","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisNkEPQ1MIyihCSP3C7W28PHOGAXAyhKjVek8T=s64","userId":"04446447163478496729"}},"outputId":"24c51d94-d9c2-4d0f-98e5-b35bdb2090fa","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pwd"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Cmput 328/Assignment5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V3Ys9jkwBBfb"},"source":["\n","import sys\n","#sys.path.append(\"drive/My Drive/Cmput 328/Assignment5\")\n","import A5_utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtXZ1e0tcTeA","executionInfo":{"status":"ok","timestamp":1605566757766,"user_tz":420,"elapsed":53822,"user":{"displayName":"菅泳钦","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisNkEPQ1MIyihCSP3C7W28PHOGAXAyhKjVek8T=s64","userId":"04446447163478496729"}},"outputId":"ba993a19-c1de-4bd5-c667-9a0202c845b7","colab":{"base_uri":"https://localhost:8080/"}},"source":["%run A5_main.py"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Using pytorch version: 1.7.0+cu101\n","Using torchvision version: 0.8.1+cu101\n","Training on GPU: Tesla T4\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Training samples: 38000\n","Validation samples: 12000\n","Labeled training samples: 7600\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","  1%|▏         | 14/1000 [00:00<00:07, 136.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loading weights from: ./checkpoints/model.pt with:\n","\tcriterion: train_acc\n","\tepoch: 44\n","\ttimestamp: 20/11/16 20:52:05\n","\n","stats:\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.142 |      2.143 |       0.000 |      2.947 |      2.947 | 5.089 |     14.687 |     3.048 |    17.735 |      10.491 |     18.829 |      2.153 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Testing...\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1000/1000 [00:07<00:00, 142.60it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Test Results:\n","\n","|      |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |    fid |     is |\n","|------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+--------+--------|\n","| test |       0.000 |      1.431 |      1.431 |       0.000 |      1.474 |      1.474 | 2.905 |      7.301 |     1.524 |     8.825 |      15.595 |     21.190 |     10.000 | -1.000 | -1.000 |\n","\n","Test Time: 2.610 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GyYB6qVwc_YH"},"source":["%load_ext tensorboard\n","%tensorboard --logdir=/content/drive/My\\ Drive/Cmput\\ 328/Assignment5/tensorboard\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GeaTRxxodt-I"},"source":["import torch\n","import pandas as pd\n","import torch.nn as nn\n","\n","from A5_utils import REAL_UNLABELED, FAKE_UNLABELED, REAL_LABEL, FAKE_LABEL\n","\n","\n","class TrainParams:\n","    \"\"\"\n","    :ivar n_workers: no. of threads for loading data\n","\n","    :ivar validate_gap: gap in epochs between validations\n","\n","    :ivar tb_path: folder where to save tensorboard data\n","\n","    :ivar load_weights:\n","        0: train from scratch,\n","        1: load and test\n","        2: load if it exists and continue training\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.n_workers = 0\n","        self.batch_size = 128\n","        self.n_epochs = 50\n","        self.load_weights = 0\n","        self.tb_path = './tensorboard'\n","        #self.weights_path =\"drive/My Drive/Cmput 328/Assignment5\"\n","        \n","        self.weights_path = './checkpoints/model.pt'\n","        self.validate_gap = 10\n","\n","\n","class OptimizerParams:\n","    def __init__(self):\n","        self.type = 0\n","        self.lr = 0.0002\n","        self.momentum = 0.9\n","        self.weight_decay = 0.0005\n","        self.beta1 = 0.5\n","\n","\n","class SharedNet(nn.Module):\n","    class Params:\n","        dummy = 0\n","\n","    def __init__(self, params, n_channels=3, img_size=32):\n","        \"\"\"\n","\n","        :param SharedNet.Params params:\n","        \"\"\"\n","        super(SharedNet, self).__init__()\n","        self.conv = nn.Sequential(\n","            # input size 3x32x32\n","            nn.Conv2d(n_channels,6,kernel_size=5),\n","            nn.LeakyReLU(0.2),\n","            # input size 6x28x28\n","            nn.Conv2d(6,12,kernel_size = 5),\n","            nn.BatchNorm2d(12),\n","            nn.LeakyReLU(0.2),\n","            # input size 12x20x20\n","            nn.Conv2d(12,24,kernel_size=5),\n","            nn.BatchNorm2d(24),\n","            nn.LeakyReLU(0.2)\n","            # output size 24x20x20\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(24*20*20,1024),\n","            nn.ReLU()\n","        )\n","\n","        #pass\n","\n","    def init_weights(self):\n","        def init_weight(m):\n","          cln = m.__class__.__name__\n","          if cln.find('Conv')!=-1:\n","            nn.init.normal_(m.weight.data,0.0,0.2)\n","          elif cln.find('BatchNorm') != -1:\n","            nn.init.normal_(m.weight.data,1.0,0.02)\n","            nn.init.constant_(m.bias.data,0)\n","        self.conv.apply(init_weight)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = x.view(x.shape[0],-1)\n","        x = self.fc(x)\n","        return x\n","\n","\n","class Discriminator(nn.Module):\n","    class Params:\n","        opt = OptimizerParams()\n","\n","    def __init__(self, params, n_channels=3, img_size=32):\n","        \"\"\"\n","\n","        :param Discriminator.Params params:\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","        #pass\n","        self.conv = nn.Sequential(\n","            # intput size 24x20x20\n","            nn.Linear(1024,1), \n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param enc_input:\n","        :return:\n","        \"\"\"\n","        #pass\n","\n","        #x = x.view(x.shape[0],-1)\n","        output = self.conv(x)\n","        output = output.reshape(-1)\n","        return output\n","\n","    def get_loss(self, dscr_out, labels):\n","        \"\"\"\n","\n","        :param dscr_out: Discriminator output\n","        :param labels: Real vs fake binary labels (real --> 1, fake --> 0)\n","        :return:\n","        \"\"\"\n","        #pass\n","        #print('size of dscr_out is',len(dscr_out),'size of lables is',len(labels),'\\n')\n","        #print(dscr_out,'\\t','labels')\n","        \n","        loss = nn.BCELoss()\n","        return loss(dscr_out,labels)\n","\n","    def get_optimizer(self, modules):\n","        \"\"\"\n","\n","        :param nn.ModuleList modules: [shared_net, discriminator, classifier, generator, composite_loss]\n","        :return:\n","        \"\"\"\n","        opt = OptimizerParams()\n","        opt_params = (list(modules[0].parameters())+list(modules[1].parameters())+list(modules[2].parameters()))\n","        \n","        return torch.optim.Adam(opt_params, lr=opt.lr, betas=(opt.beta1,0.999), weight_decay=opt.weight_decay)\n","\n","    def init_weights(self):\n","        pass\n","\n","\n","class Classifier(nn.Module):\n","    class Params:\n","        dummy = 0\n","\n","    def __init__(self, params, n_classes=20, n_channels=3, img_size=32):\n","        \"\"\"\n","\n","        :param n_classes: 10 classes for real images and 10 for fake images\n","        :param Classifier.Params params:\n","        \"\"\"\n","        super(Classifier, self).__init__()\n","        #pass\n","        self.net = nn.Sequential(\n","            nn.Linear(1024,20),\n","            #nn.Linear(256,20),\n","            nn.Softmax()\n","        )\n","\n","    def get_loss(self, cls_out, labels, is_labeled=None, n_labeled=None):\n","        \"\"\"\n","\n","        :param cls_out: Classifier output\n","        :param labels: labels for both fake and real images in range 0 - 19;\n","        -1 for real unlabeled, -2 for fake unlabeled\n","        :param is_labeled: boolean array marking which labels are valid; None when all are valid\n","        :param n_labeled: number of valid labels;  None when all are valid\n","        :return:\n","        \"\"\"\n","        #pass\n","\n","        if n_labeled and n_labeled == 0:\n","          return torch.tensor(0.,requires_grad=True)\n","\n","        loss_real = nn.CrossEntropyLoss(ignore_index=-1)\n","        loss_fake = nn.CrossEntropyLoss(ignore_index=-2)\n","        #temp = torch.tensor(0.,requires_grad=True)\n","\n","        \"\"\"for i in range(len(is_labeled)):\n","          if is_labeled[i] >= 0:\n","            print(cls_out[i].item,labels[i])\n","            temp += loss(cls_out[i],labels[i])\"\"\"\n","\n","        if -1 in labels:\n","          #print('used -1 real')\n","          return loss_real(cls_out,labels)\n","        else:\n","          #print('used -2 fake')\n","          #print(loss_fake(cls_out,labels))\n","          return loss_fake(cls_out,labels)\n","        \n","        #return loss()\n","    def init_weights(self):\n","        pass\n","\n","    def forward(self, x):\n","        #pass\n","        #x = x.view(x.shape[0],-1)\n","        x = self.net(x)\n","        #x = x.reshape(-1)\n","        return x\n","\n","class Generator(nn.Module):\n","    class Params:\n","        opt = OptimizerParams()\n","\n","    def __init__(self, params, input_size, n_channels=3, out_size=32):\n","        \"\"\"\n","\n","        :param Generator.Params params:\n","        \"\"\"\n","        super(Generator, self).__init__()\n","        \n","        self.conv = nn.Sequential(\n","            nn.ConvTranspose2d(100,256,4,1,0,bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            # state size. (ngf*8) x 4 x 4\n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # state size. (ngf*4) x 8 x 8\n","            nn.ConvTranspose2d( 128, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # state size. (ngf*2) x 16 x 16\n","            nn.ConvTranspose2d( 64, 3, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","    def forward(self, x):\n","      x = self.conv(x)\n","      #print(\"\\n output of generator is\",x.shape,\"\\n\")\n","      return x\n","\n","    def get_optimizer(self, module):\n","        \"\"\"\n","\n","        :param nn.ModuleList modules: [shared_net, discriminator, classifier, generator, composite_loss]\n","        :return:\n","        \"\"\"\n","        opt = OptimizerParams()\n","        return torch.optim.Adam(module.parameters(),lr=opt.lr, betas=(opt.beta1,0.999), weight_decay=opt.weight_decay)\n","\n","    def init_weights(self):\n","        def init_weight(m):\n","          cln = m.__class__.__name__\n","          if cln.find('Conv')!=-1:\n","            nn.init.normal_(m.weight.data,0.0,0.2)\n","          elif cln.find('BatchNorm') != -1:\n","            nn.init.normal_(m.weight.data,1.0,0.02)\n","            nn.init.constant_(m.bias.data,0)\n","        self.conv.apply(init_weight)\n","\n","\n","class CompositeLoss(nn.Module):\n","    class Params:\n","        dummy = 0\n","\n","    def __init__(self, device, params):\n","        \"\"\"\n","\n","        :param torch.device device:\n","        :param CompositeLoss.Params params:\n","        \"\"\"\n","        super(CompositeLoss, self).__init__()\n","\n","    def forward(self, dscr_loss, cls_loss):\n","        #pass\n","        x = dscr_loss+cls_loss\n","\n","        return x\n","\n","class SaveCriteria:\n","    def __init__(self, status_df):\n","        \"\"\"\n","\n","        :param pd.DataFrame status_df:\n","        \"\"\"\n","        self._opt_status_df = status_df.copy()\n","\n","    def decide(self, status_df):\n","        \"\"\"\n","        decide when to save new checkpoint while training based on training and validation stats\n","        following metrics are available:\n","      |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |\n","         cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |   is |\n","\n","         where the first 10 are losses: dscr --> discriminator, cls --> classifier, gen --> generator,\n","         cmp --> composite, real --> real images, fake --> fake images\n","\n","         acc --> classification accuracy\n","         is --> inception_score\n","\n","        :param pd.DataFrame status_df:\n","        \"\"\"\n","\n","        save_weights = 0\n","        criterion = ''\n","\n","        \"\"\"total train accuracy over real+fake images\"\"\"\n","        if status_df['total_acc']['valid'] > self._opt_status_df['total_acc']['valid']:\n","            self._opt_status_df['total_acc']['valid'] = status_df['total_acc']['valid']\n","            save_weights = 1\n","            criterion = 'valid_acc'\n","\n","        if status_df['total_acc']['train'] > self._opt_status_df['total_acc']['train']:\n","            self._opt_status_df['total_acc']['train'] = status_df['total_acc']['train']\n","            save_weights = 1\n","            criterion = 'train_acc'\n","\n","        \"\"\"composite loss on real images\"\"\"\n","        if status_df['cmp_real']['valid'] > self._opt_status_df['cmp_real']['valid']:\n","            self._opt_status_df['cmp_real']['valid'] = status_df['cmp_real']['valid']\n","            save_weights = 1\n","            criterion = 'valid_loss'\n","\n","        if status_df['cmp_real']['train'] > self._opt_status_df['cmp_real']['train']:\n","            self._opt_status_df['cmp_real']['train'] = status_df['cmp_real']['train']\n","            save_weights = 1\n","            criterion = 'train_loss'\n","\n","        return save_weights, criterion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzZ5ghYeE3L_","executionInfo":{"status":"ok","timestamp":1605560336214,"user_tz":420,"elapsed":3500715,"user":{"displayName":"菅泳钦","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisNkEPQ1MIyihCSP3C7W28PHOGAXAyhKjVek8T=s64","userId":"04446447163478496729"}},"outputId":"67120669-5ae3-41af-865c-58a13159d641","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["236fc4c4277e40798cf49671c852a91c","36f79770e709432fac5f03de1a0c0268","f7012411d3d04ec9947315fa7324a78c","356a0e6a81404409ba12b4482a1280ed","b4396577c938427ea4697f02d9931d59","552a056c286f4a3f867d9c7184641142","f0d30b336d7947e9b18b80da93e87a6d","f0f2f57d2e634f1495af3814f4149e79"]}},"source":["# new A5 Main file\n","import os\n","import re\n","import time\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","\n","import torch\n","from torchvision import transforms, datasets, version\n","\n","print('Using pytorch version: {}'.format(torch.__version__))\n","print('Using torchvision version: {}'.format(version.__version__))\n","\n","import torch.nn as nn\n","from torch.utils.data.sampler import *\n","from torch.utils.data import Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision.models.inception import inception_v3\n","from torchvision.utils import make_grid\n","\n","\"\"\"\n","hack to deal with vagaries of Colab and Google Drive in batch mode\n","\"\"\"\n","\n","\"\"\"\n","import shutil\n","\n","def rreplace(s, old, new='', occurrence=1):\n","    li = s.rsplit(old, occurrence)\n","    return new.join(li)\n","\n","\n","script_dir = os.path.dirname(os.path.abspath(__file__))\n","script_dir = script_dir.replace(os.sep, '/') + '/'\n","\n","postfixed_files = [_file for _file in os.listdir(script_dir) if\n","                   os.path.splitext(_file)[0].endswith(' (1)')]\n","if postfixed_files:\n","    print('postfixed_files: {}'.format(postfixed_files))\n","\n","    for _file in postfixed_files:\n","        _dst_file = rreplace(_file, ' (1)', '')\n","        _src_path = os.path.join(script_dir, _file)\n","        _dst_path = os.path.join(script_dir, _dst_file)\n","\n","        print('{} --> {}'.format(_file, _dst_file))\n","        shutil.move(_src_path, _dst_path)\n","\"\"\"\n","\n","#from A5_submission import SharedNet, Discriminator, Classifier, Generator, CompositeLoss\n","#from A5_submission import TrainParams, SaveCriteria\n","from A5_utils import REAL_LABEL, FAKE_LABEL, REAL_UNLABELED, FAKE_UNLABELED, print_stats\n","from A5_utils import get_num_params, PartiallyLabeled, compute_fid, compute_inception_score, GANLosses, InceptionV3\n","\n","\n","class A5_Params:\n","    \"\"\"\n","\n","\n","    :ivar gen_latent_size: Size of latent vector used as generator input\n","\n","    :ivar fid_dims: which feature map to use for FID\n","\n","    :ivar total_split: what fraction of training data to use; working on small subsets can be useful for debugging\n","\n","    :ivar train_gen_metrics: toggle computing generator metrics FID and IS during training;\n","    disabling can speed up validation\n","\n","    :ivar eval_gen_metrics: toggle computing generator metrics FID and IS during validation;\n","    disabling can speed up validation\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.use_cuda = 1\n","\n","        self.train_split = 0.76\n","        self.labeled_split = 0.2\n","\n","        self.gen_latent_size = 100\n","        self.fid_dims = 2048\n","\n","        self.train = TrainParams()\n","\n","        \"\"\"useful for debugging\"\"\"\n","        self.total_split = 1\n","        self.train_gen_metrics = 0\n","        self.eval_gen_metrics = 0\n","\n","        \"\"\"\n","        Module specific parameters\n","        \"\"\"\n","        self.shared = SharedNet.Params()\n","        self.dscr = Discriminator.Params()\n","        self.cls = Classifier.Params()\n","        self.gen = Generator.Params()\n","        self.loss = CompositeLoss.Params()\n","\n","\n","def evaluate(all_modules, dataloader, composite_loss, inception_model, fid_model, upsample,\n","             device, params, n_classes=10):\n","    \"\"\"\n","\n","    :param nn.ModuleList all_modules:\n","    :param dataloader:\n","    :param CompositeLoss composite_loss:\n","    :param int vis:\n","    :param torch.device  device:\n","    :param A5_Params  params:\n","    :return:\n","    \"\"\"\n","    all_modules.eval()\n","\n","    shared_net, discriminator, \\\n","    classifier, generator = all_modules  # type: SharedNet, Discriminator, Classifier, Generator\n","\n","    n_batches = 0\n","\n","    real_total = 0\n","    real_correct = 0\n","\n","    fake_total = 0\n","    fake_correct = 0\n","\n","    total_fid = 0\n","    total_inception_score = 0\n","\n","    total_time = 0\n","\n","    loss = GANLosses()\n","    loss_item = GANLosses()\n","    total_loss = GANLosses()\n","    mean_loss = GANLosses()\n","\n","    fake_images = fake_images_grid = None\n","    real_images = real_images_grid = None\n","\n","    print('evaluating...')\n","\n","    n_batches = len(dataloader)\n","\n","    with torch.no_grad():\n","        for batch_idx, (real_images, real_labels) in tqdm(enumerate(dataloader), total=n_batches):\n","\n","            real_images = real_images.to(device)\n","\n","            real_labels = real_labels.to(device)  # 0 to 9\n","            fake_labels = real_labels + n_classes  # 10 to 19\n","\n","            \"\"\"update discriminator  / classifier with real images\"\"\"\n","            dscr_real_labels = torch.full((real_labels.size(0),), REAL_LABEL, dtype=torch.float, device=device)\n","            dscr_fake_labels = torch.full((real_labels.size(0),), FAKE_LABEL, dtype=torch.float, device=device)\n","\n","            noise = torch.randn(real_labels.size(0), params.gen_latent_size, 1, 1, device=device)\n","\n","            start_t = time.time()\n","\n","            shared_out_real = shared_net(real_images)\n","            dscr_out_real = discriminator(shared_out_real)\n","            cls_out_real = classifier(shared_out_real)\n","\n","            \"\"\"update discriminator  / classifier with fake images\"\"\"\n","            \"\"\"Generate fake image batch with generator\"\"\"\n","            fake_images = generator(noise)\n","\n","            shared_out_fake = shared_net(fake_images)\n","            dscr_out_fake = discriminator(shared_out_fake)\n","            cls_out_fake = classifier(shared_out_fake)\n","\n","            \"\"\"time only forward passes through nets\"\"\"\n","            end_t = time.time()\n","\n","            test_time = end_t - start_t\n","            total_time += test_time\n","\n","            \"\"\"compute losses\"\"\"\n","            loss.dscr_real = discriminator.get_loss(dscr_out_real, dscr_real_labels)\n","            loss.cls_real = classifier.get_loss(cls_out_real, real_labels)\n","            loss.cmp_real = composite_loss(loss.dscr_real, loss.cls_real)\n","\n","            loss.dscr_fake = discriminator.get_loss(dscr_out_fake, dscr_fake_labels)\n","            loss.cls_fake = classifier.get_loss(cls_out_fake, fake_labels)\n","            loss.cmp_fake = composite_loss(loss.dscr_fake, loss.cls_fake)\n","\n","            \"\"\"total loss for discriminator / classifier\"\"\"\n","            loss.cmp = loss.cmp_real + loss.cmp_fake\n","\n","            \"\"\"fake labels are real for generator loss\"\"\"\n","            loss.dscr_gen = discriminator.get_loss(dscr_out_fake, dscr_real_labels)\n","            loss.cls_gen = classifier.get_loss(cls_out_fake, real_labels)\n","            loss.cmp_gen = composite_loss(loss.dscr_gen, loss.cls_gen)\n","\n","            \"\"\"classification accuracy for real images\"\"\"\n","            _, pred_real = torch.max(cls_out_real.data, 1)\n","            pred_real = pred_real.squeeze()\n","            _correct = pred_real.eq(real_labels).sum().item()\n","            _total = real_labels.size(0)\n","            real_total += _total\n","            real_correct += _correct\n","\n","            \"\"\"classification accuracy for fake images\"\"\"\n","            _, pred_fake = torch.max(cls_out_fake.data, 1)\n","            pred_fake = pred_fake.squeeze()\n","            fake_total += fake_labels.size(0)\n","            fake_correct += pred_fake.eq(fake_labels).sum().item()\n","\n","            \"\"\"Generator metrics\"\"\"\n","            if params.eval_gen_metrics:\n","                \"\"\"resize images to be compatible with inception\"\"\"\n","                real_images_up = upsample(real_images.detach())\n","                fake_images_up = upsample(fake_images.detach())\n","\n","                inception_score = compute_inception_score(fake_images_up, inception_model)\n","                inception_score = inception_score[0]\n","                fid = compute_fid([real_images_up, fake_images_up], fid_model, device=device, dims=params.fid_dims)\n","\n","                total_inception_score += inception_score\n","                total_fid += fid\n","\n","            total_loss_dict = total_loss.__dict__\n","            for loss_type in loss.__dict__:\n","                loss_item.__dict__[loss_type] = loss.__dict__[loss_type]\n","                total_loss_dict[loss_type] += loss_item.__dict__[loss_type]\n","\n","            n_batches += 1\n","\n","    for loss_type in loss.__dict__:\n","        mean_loss.__dict__[loss_type] = total_loss.__dict__[loss_type] / n_batches\n","\n","    if real_images is not None:\n","        real_images_grid = make_grid(real_images, padding=2, normalize=True)\n","\n","    if fake_images is not None:\n","        fake_images_grid = make_grid(fake_images, padding=2, normalize=True)\n","\n","    \"\"\"mean classification accuracy for real, fake and real+fake\"\"\"\n","    real_acc = 100. * real_correct / real_total\n","    fake_acc = 100. * fake_correct / fake_total\n","    total_acc = 100. * (real_correct + fake_correct) / (real_total + fake_total)\n","\n","    if params.eval_gen_metrics:\n","        total_inception_score /= n_batches\n","        total_fid /= n_batches\n","    else:\n","        total_inception_score = total_fid = -1\n","\n","    return mean_loss, (real_acc, fake_acc, total_acc), \\\n","           (total_inception_score, total_fid, real_images_grid, fake_images_grid), total_time\n","\n","\n","def main():\n","    \"\"\"number of classes in FMNIST dataset\"\"\"\n","    n_classes = 10\n","\n","    params = A5_Params()\n","\n","    # optional command line argument parsing\n","    try:\n","        import paramparse\n","    except ImportError:\n","        pass\n","    else:\n","        paramparse.process(params)\n","\n","    # init device\n","    if params.use_cuda and torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        dtype = torch.cuda.FloatTensor\n","        print('Training on GPU: {}'.format(torch.cuda.get_device_name(0)))\n","    else:\n","        device = torch.device(\"cpu\")\n","        dtype = torch.FloatTensor\n","        print('Training on CPU')\n","\n","    # load dataset\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    train_set = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n","\n","    test_set = datasets.CIFAR10('data', train=False, download=True, transform=transform)\n","\n","    valid_set = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n","\n","    train_params = params.train\n","\n","    num_train = int(len(train_set) * params.total_split)\n","    indices = list(range(num_train))\n","    split = int(np.floor(params.train_split * num_train))\n","\n","    train_idx, valid_idx = indices[:split], indices[split:]\n","    train_set = PartiallyLabeled(train_set, train_idx, labeled_percent=params.labeled_split)\n","\n","    print('Training samples: {}\\n'\n","          'Validation samples: {}\\n'\n","          'Labeled training samples: {}'\n","          ''.format(\n","        len(train_idx),\n","        len(valid_idx),\n","        train_set.n_labeled_data\n","    ))\n","\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SequentialSampler(valid_idx)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=train_params.batch_size, sampler=train_sampler,\n","                                                   num_workers=train_params.n_workers)\n","    valid_dataloader = torch.utils.data.DataLoader(valid_set, batch_size=24, sampler=valid_sampler,\n","                                                   num_workers=train_params.n_workers)\n","    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=False,\n","                                                  num_workers=train_params.n_workers)\n","\n","    # create all_modules\n","    shared_net = SharedNet(params.shared).to(device)  # type: SharedNet\n","    discriminator = Discriminator(params.dscr).to(device)  # type: Discriminator\n","    classifier = Classifier(params.cls).to(device)  # type: Classifier\n","    generator = Generator(params.gen, params.gen_latent_size).to(device)  # type: Generator\n","    composite_loss = CompositeLoss(device, params.loss).to(device)\n","\n","    assert isinstance(shared_net, nn.Module), 'SharedNet must be an instance of nn.Module'\n","    assert isinstance(discriminator, nn.Module), 'Discriminator must be an instance of nn.Module'\n","    assert isinstance(classifier, nn.Module), 'Classifier must be an instance of nn.Module'\n","    assert isinstance(generator, nn.Module), 'Generator must be an instance of nn.Module'\n","    assert isinstance(composite_loss, nn.Module), 'CompositeLoss must be an instance of nn.Module'\n","\n","    n_shared_params = get_num_params(shared_net)\n","    n_discriminator_params = get_num_params(discriminator)\n","    n_classifier_params = get_num_params(classifier)\n","\n","    assert n_shared_params >= n_discriminator_params and n_shared_params >= n_classifier_params, \\\n","        \"Discriminator and classifier must have at least half their parameters shared\"\n","\n","    all_modules = nn.ModuleList((shared_net, discriminator, classifier, generator))  # type: nn.ModuleList\n","\n","    # init weights\n","    shared_net.init_weights()\n","    discriminator.init_weights()\n","    generator.init_weights()\n","    classifier.init_weights()\n","\n","    discriminator_opt = discriminator.get_optimizer(nn.ModuleList((shared_net, discriminator, classifier)))\n","    generator_opt = generator.get_optimizer(generator)\n","\n","    weights_dir = os.path.dirname(train_params.weights_path)\n","    weights_name = os.path.basename(train_params.weights_path)\n","\n","    if not os.path.isdir(weights_dir):\n","        os.makedirs(weights_dir)\n","\n","    start_epoch = 0\n","\n","    mean_loss = GANLosses()\n","    eval_metrics = list(mean_loss.__dict__.keys()) + ['total_acc', 'real_acc', 'fake_acc', 'fid', 'is']\n","    data_types = ['train', 'valid']\n","\n","    status_df = pd.DataFrame(\n","        np.zeros((len(data_types), len(eval_metrics)), dtype=np.float32),\n","        index=data_types,\n","        columns=eval_metrics,\n","    )\n","\n","    # load weights\n","    if train_params.load_weights:\n","        matching_ckpts = [k for k in os.listdir(weights_dir) if\n","                          os.path.isfile(os.path.join(weights_dir, k)) and\n","                          k.startswith(weights_name)]\n","        if not matching_ckpts:\n","            msg = 'No checkpoints found matching {} in {}'.format(weights_name, weights_dir)\n","            if train_params.load_weights == 1:\n","                raise IOError(msg)\n","            print(msg)\n","        else:\n","            matching_ckpts.sort(key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', x)])\n","\n","            weights_path = os.path.join(weights_dir, matching_ckpts[-1])\n","\n","            chkpt = torch.load(weights_path, map_location=device)  # load checkpoint\n","\n","            print('Loading weights from: {} with:\\n'\n","                  '\\tcriterion: {}\\n'\n","                  '\\tepoch: {}\\n'\n","                  '\\ttimestamp: {}\\n'.format(\n","                weights_path,\n","                chkpt['criterion'],\n","                chkpt['epoch'],\n","                chkpt['timestamp']))\n","\n","            status_df = chkpt['status_df']\n","\n","            print('stats:')\n","            print_stats(status_df)\n","            print()\n","\n","            shared_net.load_state_dict(chkpt['shared_net'])\n","            discriminator.load_state_dict(chkpt['discriminator'])\n","            generator.load_state_dict(chkpt['generator'])\n","            classifier.load_state_dict(chkpt['classifier'])\n","            generator_opt.load_state_dict(chkpt['generator_opt'])\n","            discriminator_opt.load_state_dict(chkpt['discriminator_opt'])\n","\n","            start_epoch = chkpt['epoch'] + 1\n","    else:\n","        print('Training from scratch')\n","\n","    if params.train_gen_metrics or params.eval_gen_metrics:\n","        inception_model = inception_v3(pretrained=True, transform_input=False, init_weights=False).type(dtype)\n","        \"\"\"custom inception for FID\"\"\"\n","        block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[params.fid_dims]\n","        fid_model = InceptionV3(output_blocks=[block_idx], resize_input=False).to(device)\n","        \"\"\"needed to resize images to be compatible with inception\"\"\"\n","        upsample = nn.Upsample(size=(299, 299), mode='bilinear', align_corners=True).type(dtype)\n","    else:\n","        inception_model = fid_model = upsample = None\n","\n","    if train_params.load_weights != 1:\n","        \"\"\"\n","        continue training\n","        \"\"\"\n","\n","        writer = SummaryWriter(log_dir=params.train.tb_path)\n","        print(f'Saving tensorboard summary to: {params.train.tb_path}')\n","\n","        \"\"\"\n","        training steps from: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n","        \"\"\"\n","        iter_id = 0\n","\n","        \"\"\"decide when to save weights\"\"\"\n","        save_criteria = SaveCriteria(status_df)\n","\n","        if not params.train_gen_metrics:\n","            print('Generator metrics computation is disabled during training')\n","\n","        if not params.eval_gen_metrics:\n","            print('Generator metrics computation is disabled during evaluation')\n","\n","        for epoch in range(start_epoch, train_params.n_epochs):\n","            all_modules.train()\n","\n","            real_total = 0\n","            real_correct = 0\n","\n","            fake_total = 0\n","            fake_correct = 0\n","\n","            batch_idx = 0\n","\n","            train_fid = 0\n","            train_inception_score = 0\n","\n","            total_loss = GANLosses()\n","            loss = GANLosses()\n","            loss_item = GANLosses()\n","\n","            n_batches = len(train_dataloader)\n","\n","            for batch_idx, (real_images, real_labels, is_labeled) in tqdm(enumerate(train_dataloader), total=n_batches):\n","                real_images = real_images.to(device)\n","\n","                real_labels = real_labels.to(device)  # 0 to 9\n","                fake_labels = real_labels + n_classes  # 10 to 19\n","\n","                is_labeled = is_labeled.squeeze()\n","                n_labeled = np.count_nonzero(is_labeled.detach().numpy())\n","\n","                \"\"\"remove labels for unlabeled images\"\"\"\n","                is_not_labeled = np.logical_not(is_labeled.cpu().numpy()).squeeze()\n","                real_labels[is_not_labeled] = REAL_UNLABELED\n","                fake_labels[is_not_labeled] = FAKE_UNLABELED\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                train discriminator / classifier\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                shared_net.zero_grad()\n","                discriminator.zero_grad()\n","                classifier.zero_grad()\n","\n","                \"\"\"update discriminator  / classifier with real images\"\"\"\n","                dscr_real_labels = torch.full((real_labels.size(0),), REAL_LABEL, dtype=torch.float, device=device)\n","\n","                shared_out_real = shared_net(real_images)\n","                dscr_out_real = discriminator(shared_out_real)\n","                cls_out_real = classifier(shared_out_real)\n","\n","                loss.dscr_real = discriminator.get_loss(dscr_out_real, dscr_real_labels)\n","                loss.cls_real = classifier.get_loss(cls_out_real, real_labels, is_labeled, n_labeled)\n","                loss.cmp_real = composite_loss(loss.dscr_real, loss.cls_real)\n","\n","                \"\"\"compute gradients for the real batch\"\"\"\n","                loss.cmp_real.backward()\n","\n","                \"\"\"update discriminator  / classifier with fake images\"\"\"\n","                dscr_fake_labels = torch.full((real_labels.size(0),), FAKE_LABEL, dtype=torch.float, device=device)\n","\n","                noise = torch.randn(real_labels.size(0), params.gen_latent_size, 1, 1, device=device)\n","\n","                \"\"\"Generate fake image batch with generator\"\"\"\n","                fake_images = generator(noise)\n","\n","                \"\"\"we do not want generator gradients to be computed\"\"\"\n","                fake_images_no_grad = fake_images.detach()\n","\n","                shared_out_fake = shared_net(fake_images_no_grad)\n","                dscr_out_fake = discriminator(shared_out_fake)\n","                cls_out_fake = classifier(shared_out_fake)\n","\n","                loss.dscr_fake = discriminator.get_loss(dscr_out_fake, dscr_fake_labels)\n","                loss.cls_fake = classifier.get_loss(cls_out_fake, fake_labels, is_labeled, n_labeled)\n","                loss.cmp_fake = composite_loss(loss.dscr_fake, loss.cls_fake)\n","\n","                \"\"\"Add the gradients from the fake batch to the real one\"\"\"\n","                loss.cmp_fake.backward()\n","\n","                \"\"\"total loss for discriminator / classifier\"\"\"\n","                loss.cmp = loss.cmp_real + loss.cmp_fake\n","\n","                \"\"\"update discriminator and classifier parameters\"\"\"\n","                discriminator_opt.step()\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                train generator\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                generator.zero_grad()\n","\n","                \"\"\"Since we just updated the discriminator, perform another forward pass of all-fake batch through it\"\"\"\n","                shared_out_gen = shared_net(fake_images)\n","                dscr_out_gen = discriminator(shared_out_gen)\n","                cls_out_gen = classifier(shared_out_gen)\n","\n","                \"\"\"fake labels are real for generator loss\"\"\"\n","                loss.dscr_gen = discriminator.get_loss(dscr_out_gen, dscr_real_labels)\n","                loss.cls_gen = classifier.get_loss(cls_out_gen, real_labels, is_labeled, n_labeled)\n","                loss.cmp_gen = composite_loss(loss.dscr_gen, loss.cls_gen)\n","\n","                loss.cmp_gen.backward()\n","\n","                generator_opt.step()\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                collect train statistics and add to tensorboard log\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                total_loss_dict = total_loss.__dict__\n","                for loss_type in loss.__dict__:\n","                    loss_item.__dict__[loss_type] = loss.__dict__[loss_type]\n","                    total_loss_dict[loss_type] += loss_item.__dict__[loss_type]\n","                    writer.add_scalar(f'train_iter_loss/{loss_type}', loss_item.__dict__[loss_type], iter_id)\n","\n","                \"\"\"classification accuracy for real images\"\"\"\n","                _, pred_real = torch.max(cls_out_real.data, 1)\n","                pred_real = pred_real.squeeze()\n","                real_total += real_labels.size(0)\n","                real_correct += pred_real.eq(real_labels).sum().item()\n","\n","                \"\"\"classification accuracy for fake images\"\"\"\n","                _, pred_fake = torch.max(cls_out_fake.data, 1)\n","                pred_fake = pred_fake.squeeze()\n","                fake_total += fake_labels.size(0)\n","                fake_correct += pred_fake.eq(fake_labels).sum().item()\n","\n","                if params.train_gen_metrics:\n","                    \"\"\"resize images to be compatible with inception\"\"\"\n","                    real_images_up = upsample(real_images.detach())\n","                    fake_images_up = upsample(fake_images.detach())\n","\n","                    inception_score = compute_inception_score(fake_images_up, inception_model)\n","                    \"\"\"need only the mean KL Divergence\"\"\"\n","                    inception_score = inception_score[0]\n","                    fid = compute_fid([real_images_up, fake_images_up], fid_model, device=device, dims=params.fid_dims)\n","\n","                    train_inception_score += inception_score\n","                    train_fid += fid\n","\n","                    writer.add_scalar('train_iter/inception_score', inception_score, iter_id)\n","                    writer.add_scalar('train_iter/fid', fid, iter_id)\n","\n","                real_images_grid = make_grid(real_images, padding=2, normalize=True)\n","                fake_images_grid = make_grid(fake_images, padding=2, normalize=True)\n","\n","                writer.add_image('train/real_images', real_images_grid, epoch)\n","                writer.add_image('train/fake_images', fake_images_grid, epoch)\n","\n","                iter_id += 1\n","\n","            for loss_type in loss.__dict__:\n","                mean_loss.__dict__[loss_type] = total_loss.__dict__[loss_type] / (batch_idx + 1)\n","                writer.add_scalar(f'train_loss/{loss_type}', mean_loss.__dict__[loss_type], epoch)\n","                status_df[loss_type]['train'] = mean_loss.__dict__[loss_type]\n","\n","            \"\"\"mean classification accuracy for real, fake and real+fake\"\"\"\n","            real_acc = 100. * real_correct / real_total\n","            fake_acc = 100. * fake_correct / fake_total\n","            total_acc = 100. * (real_correct + fake_correct) / (real_total + fake_total)\n","\n","            if params.train_gen_metrics:\n","                train_inception_score /= (batch_idx + 1)\n","                train_fid /= (batch_idx + 1)\n","                writer.add_scalar('train/fid', train_fid, epoch)\n","                writer.add_scalar('train/inception_score', train_inception_score, epoch)\n","                status_df['is']['train'] = train_inception_score\n","                status_df['fid']['train'] = train_fid\n","\n","            writer.add_scalar('train/total_acc', total_acc, epoch)\n","            writer.add_scalar('train/real_acc', real_acc, epoch)\n","            writer.add_scalar('train/fake_acc', fake_acc, epoch)\n","\n","            status_df['total_acc']['train'] = total_acc\n","            status_df['real_acc']['train'] = real_acc\n","            status_df['fake_acc']['train'] = fake_acc\n","\n","            if epoch % train_params.validate_gap == 0:\n","                valid_loss, valid_acc, valid_gen, valid_time = evaluate(\n","                    all_modules, valid_dataloader, composite_loss, inception_model, fid_model, upsample, device, params)\n","                print('\\nvalidation time: {:.3f}'.format(valid_time))\n","\n","                valid_real_acc, valid_fake_acc, valid_total_acc = valid_acc\n","                valid_inception_score, valid_fid, valid_real_images_grid, valid_fake_images_grid, = valid_gen\n","\n","                for loss_type in loss.__dict__:\n","                    writer.add_scalar(f'valid_loss/{loss_type}', valid_loss.__dict__[loss_type], epoch)\n","                    status_df[loss_type]['valid'] = valid_loss.__dict__[loss_type]\n","\n","                writer.add_image('valid/real_images', valid_real_images_grid, epoch)\n","                writer.add_image('valid/fake_images', valid_fake_images_grid, epoch)\n","\n","                writer.add_scalar('valid/total_acc', valid_total_acc, epoch)\n","                writer.add_scalar('valid/real_acc', valid_real_acc, epoch)\n","                writer.add_scalar('valid/fake_acc', valid_fake_acc, epoch)\n","\n","                if params.eval_gen_metrics:\n","                    writer.add_scalar('valid/fid', valid_fid, epoch)\n","                    writer.add_scalar('valid/inception_score', valid_inception_score, epoch)\n","\n","                    status_df['is']['valid'] = valid_inception_score\n","                    status_df['fid']['valid'] = valid_fid\n","\n","                status_df['total_acc']['valid'] = valid_total_acc\n","                status_df['real_acc']['valid'] = valid_real_acc\n","                status_df['fake_acc']['valid'] = valid_fake_acc\n","            else:\n","                status_df.loc['valid', :] = 0\n","\n","            save_weights, criterion = save_criteria.decide(status_df)\n","\n","            print(\"Training results for epoch: {}:\\n\".format(epoch))\n","            print_stats(status_df)\n","            print()\n","\n","            # Save checkpoint.\n","            if save_weights:\n","                model_dict = {\n","                    'shared_net': shared_net.state_dict(),\n","                    'discriminator': discriminator.state_dict(),\n","                    'generator': generator.state_dict(),\n","                    'classifier': classifier.state_dict(),\n","                    'discriminator_opt': discriminator_opt.state_dict(),\n","                    'generator_opt': generator_opt.state_dict(),\n","                    'status_df': status_df,\n","                    'criterion': criterion,\n","                    'epoch': epoch,\n","                    'timestamp': datetime.now().strftime(\"%y/%m/%d %H:%M:%S\"),\n","                }\n","                weights_path = '{}.{:d}'.format(train_params.weights_path, epoch)\n","\n","                print(f'Saving weights for criterion {criterion} to {weights_path}')\n","                torch.save(model_dict, weights_path)\n","\n","    print('Testing...')\n","    test_loss, test_acc, test_gen, test_time = evaluate(\n","        all_modules, test_dataloader, composite_loss, inception_model, fid_model, upsample, device, params)\n","\n","    test_real_acc, test_fake_acc, test_total_acc = test_acc\n","    test_inception_score, test_fid, test_real_images_grid, test_fake_images_grid = test_gen\n","\n","    test_df = pd.DataFrame(\n","        np.zeros((1, len(eval_metrics)), dtype=np.float32),\n","        index=('test',),\n","        columns=eval_metrics,\n","    )\n","    for loss_type in test_loss.__dict__:\n","        test_df[loss_type]['test'] = test_loss.__dict__[loss_type]\n","\n","    test_df['total_acc']['test'] = test_total_acc\n","    test_df['real_acc']['test'] = test_real_acc\n","    test_df['fake_acc']['test'] = test_fake_acc\n","    test_df['is']['test'] = test_inception_score\n","    test_df['fid']['test'] = test_fid\n","\n","    print(\"Test Results:\\n\")\n","    print_stats(test_df)\n","    print()\n","    print('Test Time: {:.3f} sec'.format(test_time))\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using pytorch version: 1.7.0+cu101\n","Using torchvision version: 0.8.1+cu101\n","Training on GPU: Tesla T4\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"236fc4c4277e40798cf49671c852a91c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/cifar-10-python.tar.gz to data\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Training samples: 38000\n","Validation samples: 12000\n","Labeled training samples: 7600\n","Training from scratch\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving tensorboard summary to: ./tensorboard\n","Generator metrics computation is disabled during training\n","Generator metrics computation is disabled during evaluation\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","100%|██████████| 297/297 [01:37<00:00,  3.05it/s]\n","  2%|▏         | 10/500 [00:00<00:04, 98.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 95.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","validation time: 1.056\n","Training results for epoch: 0:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.019 |      2.801 |      2.820 |       0.019 |      2.970 |      2.988 | 5.809 |      6.791 |     3.057 |     9.848 |       3.741 |      5.563 |      1.918 | 0.000 | 0.000 |\n","| valid |       0.004 |      1.413 |      1.416 |       0.013 |      1.483 |      1.496 | 2.913 |      2.112 |     1.533 |     3.645 |      17.667 |     25.108 |     10.225 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_loss to ./checkpoints/model.pt.0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:36<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 1:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.002 |      2.723 |      2.725 |       0.002 |      2.960 |      2.962 | 5.687 |      6.955 |     3.055 |    10.010 |       4.487 |      7.066 |      1.908 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:36<00:00,  3.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 2:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.004 |      2.678 |      2.682 |       0.004 |      2.962 |      2.965 | 5.648 |      7.243 |     3.052 |    10.295 |       5.017 |      8.105 |      1.929 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.2\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:35<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 3:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.092 |      2.655 |      2.747 |       0.084 |      2.959 |      3.042 | 5.789 |      6.103 |     3.045 |     9.149 |       5.316 |      8.737 |      1.895 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:32<00:00,  3.22it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 4:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.011 |      2.618 |      2.630 |       0.009 |      2.958 |      2.967 | 5.597 |      6.912 |     3.050 |     9.962 |       5.696 |      9.403 |      1.989 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:33<00:00,  3.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 5:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.052 |      2.590 |      2.642 |       0.026 |      2.959 |      2.985 | 5.627 |      6.903 |     3.047 |     9.949 |       6.017 |     10.084 |      1.950 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:34<00:00,  3.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 6:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.007 |      2.557 |      2.563 |       0.008 |      2.959 |      2.968 | 5.531 |      6.942 |     3.046 |     9.989 |       6.275 |     10.755 |      1.795 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:08<00:00,  4.32it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 7:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.002 |      2.527 |      2.529 |       0.010 |      2.955 |      2.965 | 5.493 |      7.498 |     3.042 |    10.540 |       6.657 |     11.253 |      2.061 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.7\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 8:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.493 |      2.494 |       0.002 |      2.952 |      2.954 | 5.448 |      9.106 |     3.046 |    12.153 |       6.995 |     11.934 |      2.055 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.8\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 9:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.463 |      2.463 |       0.001 |      2.951 |      2.952 | 5.415 |      9.872 |     3.047 |    12.919 |       7.271 |     12.489 |      2.053 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.9\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.46it/s]\n","  2%|▏         | 10/500 [00:00<00:05, 96.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 87.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","validation time: 1.191\n","Training results for epoch: 10:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |    cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+--------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.441 |      2.441 |       0.001 |      2.950 |      2.951 |  5.393 |      9.883 |     3.048 |    12.931 |       7.539 |     13.013 |      2.066 | 0.000 | 0.000 |\n","| valid |       0.000 |      1.487 |      1.487 |      50.000 |      1.534 |     51.535 | 53.022 |      0.000 |     1.485 |     1.485 |       5.167 |     10.333 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion valid_loss to ./checkpoints/model.pt.10\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 11:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.415 |      2.416 |       0.001 |      2.951 |      2.952 | 5.368 |      9.962 |     3.048 |    13.009 |       7.779 |     13.553 |      2.005 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 12:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.389 |      2.389 |       0.001 |      2.950 |      2.950 | 5.340 |      9.907 |     3.049 |    12.955 |       8.067 |     14.050 |      2.084 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.12\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 13:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.003 |      2.378 |      2.381 |       0.014 |      2.951 |      2.965 | 5.346 |     10.294 |     3.048 |    13.342 |       8.204 |     14.347 |      2.061 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.13\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 14:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.002 |      2.361 |      2.363 |       0.005 |      2.953 |      2.959 | 5.322 |     15.644 |     3.052 |    18.697 |       8.397 |     14.703 |      2.092 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.14\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.45it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 15:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.017 |      2.365 |      2.382 |       0.041 |      2.951 |      2.993 | 5.374 |     10.644 |     3.049 |    13.693 |       8.339 |     14.671 |      2.008 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 16:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.003 |      2.340 |      2.342 |       0.003 |      2.951 |      2.955 | 5.297 |      9.801 |     3.049 |    12.850 |       8.568 |     15.121 |      2.016 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.16\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:07<00:00,  4.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 17:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.004 |      2.325 |      2.329 |       0.006 |      2.953 |      2.960 | 5.288 |     16.598 |     3.052 |    19.650 |       8.643 |     15.389 |      1.897 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.17\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:08<00:00,  4.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 18:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.310 |      2.312 |       0.002 |      2.963 |      2.964 | 5.276 |     42.017 |     3.064 |    45.082 |       8.828 |     15.608 |      2.047 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.18\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:08<00:00,  4.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 19:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.298 |      2.298 |       0.000 |      2.979 |      2.979 | 5.277 |     61.219 |     3.077 |    64.296 |       8.878 |     15.779 |      1.976 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.19\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:08<00:00,  4.36it/s]\n","  2%|▏         | 9/500 [00:00<00:05, 82.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 91.83it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","validation time: 1.105\n","Training results for epoch: 20:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |    cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+--------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.003 |      2.294 |      2.297 |       0.003 |      2.959 |      2.962 |  5.259 |     29.735 |     3.056 |    32.791 |       8.978 |     15.995 |      1.961 | 0.000 | 0.000 |\n","| valid |       0.000 |      1.487 |      1.487 |      50.000 |      1.539 |     51.539 | 53.026 |      0.000 |     1.488 |     1.488 |       5.225 |     10.450 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.20\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.44it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 21:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.009 |      2.307 |      2.316 |       0.006 |      2.963 |      2.970 | 5.286 |     40.362 |     3.063 |    43.425 |       8.920 |     15.853 |      1.987 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:06<00:00,  4.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 22:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.265 |      2.265 |       0.000 |      2.973 |      2.973 | 5.238 |     62.934 |     3.068 |    66.002 |       9.253 |     16.618 |      1.887 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.22\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:03<00:00,  4.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 23:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.241 |      2.242 |       0.001 |      2.957 |      2.958 | 5.200 |     46.745 |     3.056 |    49.800 |       9.536 |     17.050 |      2.021 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.23\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:05<00:00,  4.54it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 24:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.228 |      2.228 |       0.001 |      2.964 |      2.965 | 5.193 |     41.023 |     3.066 |    44.089 |       9.662 |     17.337 |      1.987 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.24\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:02<00:00,  4.73it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 25:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.003 |      2.223 |      2.225 |       0.005 |      2.950 |      2.954 | 5.180 |     10.591 |     3.048 |    13.639 |       9.708 |     17.447 |      1.968 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.25\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.83it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 26:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.212 |      2.213 |       0.001 |      2.951 |      2.952 | 5.165 |      9.956 |     3.049 |    13.005 |       9.758 |     17.605 |      1.911 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.26\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.81it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 27:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.204 |      2.204 |       0.000 |      2.949 |      2.949 | 5.153 |     10.078 |     3.049 |    13.127 |       9.878 |     17.753 |      2.003 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.27\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.85it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 28:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.205 |      2.205 |       0.000 |      2.949 |      2.950 | 5.155 |     10.221 |     3.048 |    13.269 |       9.884 |     17.766 |      2.003 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.28\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.84it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 29:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.208 |      2.208 |       0.000 |      2.950 |      2.951 | 5.159 |     10.394 |     3.049 |    13.443 |       9.918 |     17.729 |      2.108 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.29\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:03<00:00,  4.71it/s]\n","  2%|▏         | 11/500 [00:00<00:04, 107.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:04<00:00, 103.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","validation time: 0.981\n","Training results for epoch: 30:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |    cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+--------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.203 |      2.203 |       0.000 |      2.949 |      2.950 |  5.152 |     10.416 |     3.048 |    13.465 |       9.924 |     17.853 |      1.995 | 0.000 | 0.000 |\n","| valid |       0.000 |      1.489 |      1.489 |      50.000 |      1.539 |     51.539 | 53.028 |      0.000 |     1.488 |     1.488 |       5.046 |     10.092 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion valid_loss to ./checkpoints/model.pt.30\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.87it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 31:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.199 |      2.199 |       0.000 |      2.949 |      2.950 | 5.148 |     10.746 |     3.049 |    13.795 |       9.937 |     17.882 |      1.992 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.31\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.88it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 32:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.002 |      2.199 |      2.201 |       0.004 |      2.949 |      2.952 | 5.153 |     11.077 |     3.049 |    14.125 |       9.987 |     17.882 |      2.092 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.32\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.83it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 33:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.186 |      2.186 |       0.001 |      2.949 |      2.950 | 5.136 |     10.434 |     3.050 |    13.484 |      10.084 |     18.118 |      2.050 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.33\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.81it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 34:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.178 |      2.178 |       0.000 |      2.950 |      2.950 | 5.129 |     10.394 |     3.050 |    13.445 |      10.150 |     18.205 |      2.095 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.34\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.85it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 35:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.172 |      2.172 |       0.000 |      2.950 |      2.950 | 5.122 |     10.922 |     3.049 |    13.971 |      10.172 |     18.274 |      2.071 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.35\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.94it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 36:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.171 |      2.172 |       0.000 |      2.949 |      2.949 | 5.121 |     10.957 |     3.049 |    14.006 |      10.182 |     18.334 |      2.029 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.36\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.91it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 37:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.191 |      2.191 |       0.000 |      2.951 |      2.951 | 5.142 |     11.182 |     3.048 |    14.231 |      10.025 |     18.095 |      1.955 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:04<00:00,  4.60it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 38:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.189 |      2.190 |       0.001 |      2.950 |      2.951 | 5.141 |     11.158 |     3.049 |    14.206 |      10.029 |     18.076 |      1.982 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.92it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 39:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.172 |      2.172 |       0.000 |      2.950 |      2.950 | 5.122 |     11.220 |     3.048 |    14.269 |      10.166 |     18.355 |      1.976 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.93it/s]\n","  2%|▏         | 11/500 [00:00<00:04, 105.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:04<00:00, 101.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","validation time: 0.999\n","Training results for epoch: 40:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.167 |      2.167 |       0.000 |      2.950 |      2.950 | 5.117 |     10.940 |     3.049 |    13.989 |      10.239 |     18.421 |      2.058 | 0.000 | 0.000 |\n","| valid |       0.000 |      1.487 |      1.487 |       1.006 |      1.484 |      2.490 | 3.977 |      0.072 |     1.517 |     1.589 |      10.296 |     10.367 |     10.225 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.40\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:00<00:00,  4.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 41:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.157 |      2.157 |       0.000 |      2.948 |      2.948 | 5.105 |     11.631 |     3.049 |    14.679 |      10.332 |     18.532 |      2.132 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.41\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.85it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 42:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.012 |      2.205 |      2.217 |       0.285 |      2.952 |      3.238 | 5.455 |     17.019 |     3.051 |    20.071 |       9.804 |     17.624 |      1.984 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:03<00:00,  4.66it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 43:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.004 |      2.232 |      2.237 |       0.056 |      2.958 |      3.014 | 5.251 |     27.545 |     3.057 |    30.603 |       9.716 |     17.368 |      2.063 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.84it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 44:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.161 |      2.161 |       0.001 |      2.952 |      2.954 | 5.115 |     10.537 |     3.050 |    13.587 |      10.270 |     18.526 |      2.013 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.83it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 45:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.001 |      2.152 |      2.153 |       0.004 |      2.952 |      2.956 | 5.109 |     10.464 |     3.050 |    13.514 |      10.300 |     18.618 |      1.982 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:01<00:00,  4.86it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 46:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.148 |      2.148 |       0.000 |      2.949 |      2.949 | 5.097 |     10.658 |     3.051 |    13.708 |      10.382 |     18.661 |      2.103 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Saving weights for criterion train_acc to ./checkpoints/model.pt.46\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:02<00:00,  4.73it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 47:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.146 |      2.146 |       0.000 |      2.949 |      2.949 | 5.096 |     11.251 |     3.048 |    14.300 |      10.357 |     18.684 |      2.029 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:05<00:00,  4.54it/s]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 48:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.145 |      2.145 |       0.000 |      2.949 |      2.949 | 5.094 |     10.247 |     3.048 |    13.295 |      10.350 |     18.703 |      1.997 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 297/297 [01:08<00:00,  4.34it/s]\n","  2%|▏         | 18/1000 [00:00<00:05, 174.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training results for epoch: 49:\n","\n","|       |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |   fid |    is |\n","|-------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+-------+-------|\n","| train |       0.000 |      2.199 |      2.199 |       0.000 |      2.950 |      2.950 | 5.149 |      9.767 |     3.049 |    12.816 |      10.013 |     17.968 |      2.058 | 0.000 | 0.000 |\n","| valid |       0.000 |      0.000 |      0.000 |       0.000 |      0.000 |      0.000 | 0.000 |      0.000 |     0.000 |     0.000 |       0.000 |      0.000 |      0.000 | 0.000 | 0.000 |\n","\n","Testing...\n","evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1000/1000 [00:06<00:00, 151.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["Test Results:\n","\n","|      |   dscr_real |   cls_real |   cmp_real |   dscr_fake |   cls_fake |   cmp_fake |   cmp |   dscr_gen |   cls_gen |   cmp_gen |   total_acc |   real_acc |   fake_acc |    fid |     is |\n","|------+-------------+------------+------------+-------------+------------+------------+-------+------------+-----------+-----------+-------------+------------+------------+--------+--------|\n","| test |       0.000 |      1.479 |      1.479 |       0.002 |      1.478 |      1.480 | 2.959 |      2.792 |     1.527 |     4.320 |      10.570 |     11.140 |     10.000 | -1.000 | -1.000 |\n","\n","Test Time: 2.236 sec\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OvGwoC5rVkyI"},"source":["loss 直接加的话test结果real-acc = 32.xx\n","\n","\n","loss 取均值的结果 = ?"]},{"cell_type":"code","metadata":{"id":"hNHGL-KmddpS","cellView":"form"},"source":["#@title\n","import os\n","import re\n","import time\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","\n","import torch\n","from torchvision import transforms, datasets, version\n","\n","print('Using pytorch version: {}'.format(torch.__version__))\n","print('Using torchvision version: {}'.format(version.__version__))\n","\n","import torch.nn as nn\n","from torch.utils.data.sampler import *\n","from torch.utils.data import Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision.models.inception import inception_v3\n","from torchvision.utils import make_grid\n","\n","\"\"\"\n","hack to deal with vagaries of Colab and Google Drive in batch mode\n","\"\"\"\n","\n","\"\"\"\n","import shutil\n","\n","def rreplace(s, old, new='', occurrence=1):\n","    li = s.rsplit(old, occurrence)\n","    return new.join(li)\n","\n","\n","script_dir = os.path.dirname(os.path.abspath(__file__))\n","script_dir = script_dir.replace(os.sep, '/') + '/'\n","\n","postfixed_files = [_file for _file in os.listdir(script_dir) if\n","                   os.path.splitext(_file)[0].endswith(' (1)')]\n","if postfixed_files:\n","    print('postfixed_files: {}'.format(postfixed_files))\n","\n","    for _file in postfixed_files:\n","        _dst_file = rreplace(_file, ' (1)', '')\n","        _src_path = os.path.join(script_dir, _file)\n","        _dst_path = os.path.join(script_dir, _dst_file)\n","\n","        print('{} --> {}'.format(_file, _dst_file))\n","        shutil.move(_src_path, _dst_path)\n","\"\"\"\n","\n","#from A5_submission import SharedNet, Discriminator, Classifier, Generator, CompositeLoss\n","#from A5_submission import TrainParams, SaveCriteria\n","from A5_utils import REAL_LABEL, FAKE_LABEL, REAL_UNLABELED, FAKE_UNLABELED, print_stats\n","from A5_utils import get_num_params, PartiallyLabeled, compute_fid, compute_inception_score, GANLosses, InceptionV3\n","\n","\n","class A5_Params:\n","    \"\"\"\n","\n","\n","    :ivar gen_latent_size: Size of latent vector used as generator input\n","\n","    :ivar fid_dims: which feature map to use for FID\n","\n","    :ivar total_split: what fraction of training data to use; working on small subsets can be useful for debugging\n","\n","    :ivar train_gen_metrics: toggle computing generator metrics FID and IS during training;\n","    disabling can speed up validation\n","\n","    :ivar eval_gen_metrics: toggle computing generator metrics FID and IS during validation;\n","    disabling can speed up validation\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.use_cuda = 1\n","\n","        self.train_split = 0.76\n","        self.labeled_split = 0.2\n","\n","        self.gen_latent_size = 100\n","        self.fid_dims = 2048\n","\n","        self.train = TrainParams()\n","\n","        \"\"\"useful for debugging\"\"\"\n","        self.total_split = 0.1\n","        self.train_gen_metrics = 0\n","        self.eval_gen_metrics = 0\n","\n","        \"\"\"\n","        Module specific parameters\n","        \"\"\"\n","        self.shared = SharedNet.Params()\n","        self.dscr = Discriminator.Params()\n","        self.cls = Classifier.Params()\n","        self.gen = Generator.Params()\n","        self.loss = CompositeLoss.Params()\n","\n","\n","def evaluate(all_modules, dataloader, composite_loss, inception_model, fid_model, upsample,\n","             device, params, n_classes=10):\n","    \"\"\"\n","\n","    :param nn.ModuleList all_modules:\n","    :param dataloader:\n","    :param CompositeLoss composite_loss:\n","    :param int vis:\n","    :param torch.device  device:\n","    :param A5_Params  params:\n","    :return:\n","    \"\"\"\n","    all_modules.eval()\n","\n","    shared_net, discriminator, \\\n","    classifier, generator = all_modules  # type: SharedNet, Discriminator, Classifier, Generator\n","\n","    n_batches = 0\n","\n","    real_total = 0\n","    real_correct = 0\n","\n","    fake_total = 0\n","    fake_correct = 0\n","\n","    total_fid = 0\n","    total_inception_score = 0\n","\n","    total_time = 0\n","\n","    loss = GANLosses()\n","    loss_item = GANLosses()\n","    total_loss = GANLosses()\n","    mean_loss = GANLosses()\n","\n","    fake_images = fake_images_grid = None\n","    real_images = real_images_grid = None\n","\n","    print('evaluating...')\n","\n","    n_batches = len(dataloader)\n","\n","    with torch.no_grad():\n","        for batch_idx, (real_images, real_labels) in tqdm(enumerate(dataloader), total=n_batches):\n","\n","            real_images = real_images.to(device)\n","\n","            real_labels = real_labels.to(device)  # 0 to 9\n","            fake_labels = real_labels + n_classes  # 10 to 19\n","\n","            \"\"\"update discriminator  / classifier with real images\"\"\"\n","            dscr_real_labels = torch.full((real_labels.size(0),), REAL_LABEL, dtype=torch.float, device=device)\n","            dscr_fake_labels = torch.full((real_labels.size(0),), FAKE_LABEL, dtype=torch.float, device=device)\n","\n","            noise = torch.randn(real_labels.size(0), params.gen_latent_size, 1, 1, device=device)\n","\n","            start_t = time.time()\n","\n","            shared_out_real = shared_net(real_images)\n","            dscr_out_real = discriminator(shared_out_real)\n","            cls_out_real = classifier(shared_out_real)\n","\n","            \"\"\"update discriminator  / classifier with fake images\"\"\"\n","            \"\"\"Generate fake image batch with generator\"\"\"\n","            fake_images = generator(noise)\n","\n","            shared_out_fake = shared_net(fake_images)\n","            dscr_out_fake = discriminator(shared_out_fake)\n","            cls_out_fake = classifier(shared_out_fake)\n","\n","            \"\"\"time only forward passes through nets\"\"\"\n","            end_t = time.time()\n","\n","            test_time = end_t - start_t\n","            total_time += test_time\n","\n","            \"\"\"compute losses\"\"\"\n","            loss.dscr_real = discriminator.get_loss(dscr_out_real, dscr_real_labels)\n","            loss.cls_real = classifier.get_loss(cls_out_real, real_labels)\n","            loss.cmp_real = composite_loss(loss.dscr_real, loss.cls_real)\n","\n","            loss.dscr_fake = discriminator.get_loss(dscr_out_fake, dscr_fake_labels)\n","            loss.cls_fake = classifier.get_loss(cls_out_fake, fake_labels)\n","            loss.cmp_fake = composite_loss(loss.dscr_fake, loss.cls_fake)\n","\n","            \"\"\"total loss for discriminator / classifier\"\"\"\n","            loss.cmp = loss.cmp_real + loss.cmp_fake\n","\n","            \"\"\"fake labels are real for generator loss\"\"\"\n","            loss.dscr_gen = discriminator.get_loss(dscr_out_fake, dscr_real_labels)\n","            loss.cls_gen = classifier.get_loss(cls_out_fake, real_labels)\n","            loss.cmp_gen = composite_loss(loss.dscr_gen, loss.cls_gen)\n","\n","            \"\"\"classification accuracy for real images\"\"\"\n","            _, pred_real = torch.max(cls_out_real.data, 1)\n","            pred_real = pred_real.squeeze()\n","            _correct = pred_real.eq(real_labels).sum().item()\n","            _total = real_labels.size(0)\n","            real_total += _total\n","            real_correct += _correct\n","\n","            \"\"\"classification accuracy for fake images\"\"\"\n","            _, pred_fake = torch.max(cls_out_fake.data, 1)\n","            pred_fake = pred_fake.squeeze()\n","            fake_total += fake_labels.size(0)\n","            fake_correct += pred_fake.eq(fake_labels).sum().item()\n","\n","            \"\"\"Generator metrics\"\"\"\n","            if params.eval_gen_metrics:\n","                \"\"\"resize images to be compatible with inception\"\"\"\n","                real_images_up = upsample(real_images.detach())\n","                fake_images_up = upsample(fake_images.detach())\n","\n","                inception_score = compute_inception_score(fake_images_up, inception_model)\n","                inception_score = inception_score[0]\n","                fid = compute_fid([real_images_up, fake_images_up], fid_model, device=device, dims=params.fid_dims)\n","\n","                total_inception_score += inception_score\n","                total_fid += fid\n","\n","            total_loss_dict = total_loss.__dict__\n","            for loss_type in loss.__dict__:\n","                loss_item.__dict__[loss_type] = loss.__dict__[loss_type]\n","                total_loss_dict[loss_type] += loss_item.__dict__[loss_type]\n","\n","            n_batches += 1\n","\n","    for loss_type in loss.__dict__:\n","        mean_loss.__dict__[loss_type] = total_loss.__dict__[loss_type] / n_batches\n","\n","    if real_images is not None:\n","        real_images_grid = make_grid(real_images, padding=2, normalize=True)\n","\n","    if fake_images is not None:\n","        fake_images_grid = make_grid(fake_images, padding=2, normalize=True)\n","\n","    \"\"\"mean classification accuracy for real, fake and real+fake\"\"\"\n","    real_acc = 100. * real_correct / real_total\n","    fake_acc = 100. * fake_correct / fake_total\n","    total_acc = 100. * (real_correct + fake_correct) / (real_total + fake_total)\n","\n","    if params.eval_gen_metrics:\n","        total_inception_score /= n_batches\n","        total_fid /= n_batches\n","    else:\n","        total_inception_score = total_fid = -1\n","\n","    return mean_loss, (real_acc, fake_acc, total_acc), \\\n","           (total_inception_score, total_fid, real_images_grid, fake_images_grid), total_time\n","\n","\n","def main():\n","    \"\"\"number of classes in FMNIST dataset\"\"\"\n","    n_classes = 10\n","\n","    params = A5_Params()\n","\n","    # optional command line argument parsing\n","    try:\n","        import paramparse\n","    except ImportError:\n","        pass\n","    else:\n","        paramparse.process(params)\n","\n","    # init device\n","    if params.use_cuda and torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        dtype = torch.cuda.FloatTensor\n","        print('Training on GPU: {}'.format(torch.cuda.get_device_name(0)))\n","    else:\n","        device = torch.device(\"cpu\")\n","        dtype = torch.FloatTensor\n","        print('Training on CPU')\n","\n","    # load dataset\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    train_set = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n","\n","    test_set = datasets.CIFAR10('data', train=False, download=True, transform=transform)\n","\n","    valid_set = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n","\n","    train_params = params.train\n","\n","    num_train = int(len(train_set) * params.total_split)\n","    indices = list(range(num_train))\n","    split = int(np.floor(params.train_split * num_train))\n","\n","    train_idx, valid_idx = indices[:split], indices[split:]\n","    train_set = PartiallyLabeled(train_set, train_idx, labeled_percent=params.labeled_split)\n","\n","    print('Training samples: {}\\n'\n","          'Validation samples: {}\\n'\n","          'Labeled training samples: {}'\n","          ''.format(\n","        len(train_idx),\n","        len(valid_idx),\n","        train_set.n_labeled_data\n","    ))\n","\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SequentialSampler(valid_idx)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=train_params.batch_size, sampler=train_sampler,\n","                                                   num_workers=train_params.n_workers)\n","    valid_dataloader = torch.utils.data.DataLoader(valid_set, batch_size=24, sampler=valid_sampler,\n","                                                   num_workers=train_params.n_workers)\n","    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=False,\n","                                                  num_workers=train_params.n_workers)\n","\n","    # create all_modules\n","    shared_net = SharedNet(params.shared).to(device)  # type: SharedNet\n","    discriminator = Discriminator(params.dscr).to(device)  # type: Discriminator\n","    classifier = Classifier(params.cls).to(device)  # type: Classifier\n","    generator = Generator(params.gen, params.gen_latent_size).to(device)  # type: Generator\n","    composite_loss = CompositeLoss(device, params.loss).to(device)\n","\n","    assert isinstance(shared_net, nn.Module), 'SharedNet must be an instance of nn.Module'\n","    assert isinstance(discriminator, nn.Module), 'Discriminator must be an instance of nn.Module'\n","    assert isinstance(classifier, nn.Module), 'Classifier must be an instance of nn.Module'\n","    assert isinstance(generator, nn.Module), 'Generator must be an instance of nn.Module'\n","    assert isinstance(composite_loss, nn.Module), 'CompositeLoss must be an instance of nn.Module'\n","\n","    n_shared_params = get_num_params(shared_net)\n","    n_discriminator_params = get_num_params(discriminator)\n","    n_classifier_params = get_num_params(classifier)\n","\n","    assert n_shared_params >= n_discriminator_params and n_shared_params >= n_classifier_params, \\\n","        \"Discriminator and classifier must have at least half their parameters shared\"\n","\n","    all_modules = nn.ModuleList((shared_net, discriminator, classifier, generator))  # type: nn.ModuleList\n","\n","    # init weights\n","    shared_net.init_weights()\n","    discriminator.init_weights()\n","    generator.init_weights()\n","    classifier.init_weights()\n","\n","    discriminator_opt = discriminator.get_optimizer(nn.ModuleList((shared_net, discriminator, classifier)))\n","    generator_opt = generator.get_optimizer(generator)\n","\n","    weights_dir = os.path.dirname(train_params.weights_path)\n","    weights_name = os.path.basename(train_params.weights_path)\n","\n","    if not os.path.isdir(weights_dir):\n","        os.makedirs(weights_dir)\n","\n","    start_epoch = 0\n","\n","    mean_loss = GANLosses()\n","    eval_metrics = list(mean_loss.__dict__.keys()) + ['total_acc', 'real_acc', 'fake_acc', 'fid', 'is']\n","    data_types = ['train', 'valid']\n","\n","    status_df = pd.DataFrame(\n","        np.zeros((len(data_types), len(eval_metrics)), dtype=np.float32),\n","        index=data_types,\n","        columns=eval_metrics,\n","    )\n","\n","    # load weights\n","    if train_params.load_weights:\n","        matching_ckpts = [k for k in os.listdir(weights_dir) if\n","                          os.path.isfile(os.path.join(weights_dir, k)) and\n","                          k.startswith(weights_name)]\n","        if not matching_ckpts:\n","            msg = 'No checkpoints found matching {} in {}'.format(weights_name, weights_dir)\n","            if train_params.load_weights == 1:\n","                raise IOError(msg)\n","            print(msg)\n","        else:\n","            matching_ckpts.sort(key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', x)])\n","\n","            weights_path = os.path.join(weights_dir, matching_ckpts[-1])\n","\n","            chkpt = torch.load(weights_path, map_location=device)  # load checkpoint\n","\n","            print('Loading weights from: {} with:\\n'\n","                  '\\tcriterion: {}\\n'\n","                  '\\tepoch: {}\\n'\n","                  '\\ttimestamp: {}\\n'.format(\n","                weights_path,\n","                chkpt['criterion'],\n","                chkpt['epoch'],\n","                chkpt['timestamp']))\n","\n","            status_df = chkpt['status_df']\n","\n","            print('stats:')\n","            print_stats(status_df)\n","            print()\n","\n","            discriminator.load_state_dict(chkpt['discriminator'])\n","            generator.load_state_dict(chkpt['generator'])\n","            classifier.load_state_dict(chkpt['classifier'])\n","            generator_opt.load_state_dict(chkpt['generator_opt'])\n","            discriminator_opt.load_state_dict(chkpt['discriminator_opt'])\n","\n","            start_epoch = chkpt['epoch'] + 1\n","    else:\n","        print('Training from scratch')\n","\n","    if params.train_gen_metrics or params.eval_gen_metrics:\n","        inception_model = inception_v3(pretrained=True, transform_input=False, init_weights=False).type(dtype)\n","        \"\"\"custom inception for FID\"\"\"\n","        block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[params.fid_dims]\n","        fid_model = InceptionV3(output_blocks=[block_idx], resize_input=False).to(device)\n","        \"\"\"needed to resize images to be compatible with inception\"\"\"\n","        upsample = nn.Upsample(size=(299, 299), mode='bilinear', align_corners=True).type(dtype)\n","    else:\n","        inception_model = fid_model = upsample = None\n","\n","    if train_params.load_weights != 1:\n","        \"\"\"\n","        continue training\n","        \"\"\"\n","\n","        writer = SummaryWriter(log_dir=params.train.tb_path)\n","        print(f'Saving tensorboard summary to: {params.train.tb_path}')\n","\n","        \"\"\"\n","        training steps from: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n","        \"\"\"\n","        iter_id = 0\n","\n","        \"\"\"decide when to save weights\"\"\"\n","        save_criteria = SaveCriteria(status_df)\n","\n","        if not params.train_gen_metrics:\n","            print('Generator metrics computation is disabled during training')\n","\n","        if not params.eval_gen_metrics:\n","            print('Generator metrics computation is disabled during evaluation')\n","\n","        for epoch in range(start_epoch, train_params.n_epochs):\n","            all_modules.train()\n","\n","            real_total = 0\n","            real_correct = 0\n","\n","            fake_total = 0\n","            fake_correct = 0\n","\n","            batch_idx = 0\n","\n","            train_fid = 0\n","            train_inception_score = 0\n","\n","            total_loss = GANLosses()\n","            loss = GANLosses()\n","            loss_item = GANLosses()\n","\n","            n_batches = len(train_dataloader)\n","\n","            for batch_idx, (real_images, real_labels, is_labeled) in tqdm(enumerate(train_dataloader), total=n_batches):\n","                real_images = real_images.to(device)\n","\n","                real_labels = real_labels.to(device)  # 0 to 9\n","                fake_labels = real_labels + n_classes  # 10 to 19\n","\n","                is_labeled = is_labeled.squeeze()\n","                n_labeled = np.count_nonzero(is_labeled.detach().numpy())\n","\n","                \"\"\"remove labels for unlabeled images\"\"\"\n","                is_not_labeled = np.logical_not(is_labeled.cpu().numpy()).squeeze()\n","                real_labels[is_not_labeled] = REAL_UNLABELED\n","                fake_labels[is_not_labeled] = FAKE_UNLABELED\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                train discriminator / classifier\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                shared_net.zero_grad()\n","                discriminator.zero_grad()\n","                classifier.zero_grad()\n","\n","                \"\"\"update discriminator  / classifier with real images\"\"\"\n","                dscr_real_labels = torch.full((real_labels.size(0),), REAL_LABEL, dtype=torch.float, device=device)\n","\n","                shared_out_real = shared_net(real_images)\n","                dscr_out_real = discriminator(shared_out_real)\n","                cls_out_real = classifier(shared_out_real)\n","\n","                loss.dscr_real = discriminator.get_loss(dscr_out_real, dscr_real_labels)\n","                loss.cls_real = classifier.get_loss(cls_out_real, real_labels, is_labeled, n_labeled)\n","                x = composite_loss(loss.dscr_real, loss.cls_real)\n","                #print('the composite loss in main is',x)\n","                loss.cmp_real = composite_loss(loss.dscr_real, loss.cls_real)\n","\n","                \"\"\"compute gradients for the real batch\"\"\"\n","                loss.cmp_real.backward()\n","\n","                \"\"\"update discriminator  / classifier with fake images\"\"\"\n","                dscr_fake_labels = torch.full((real_labels.size(0),), FAKE_LABEL, dtype=torch.float, device=device)\n","\n","                noise = torch.randn(real_labels.size(0), params.gen_latent_size, 1, 1, device=device)\n","\n","                \"\"\"Generate fake image batch with generator\"\"\"\n","                fake_images = generator(noise)\n","\n","                \"\"\"we do not want generator gradients to be computed\"\"\"\n","                fake_images_no_grad = fake_images.detach()\n","\n","                shared_out_fake = shared_net(fake_images_no_grad)\n","                dscr_out_fake = discriminator(shared_out_fake)\n","                cls_out_fake = classifier(shared_out_fake)\n","\n","                loss.dscr_fake = discriminator.get_loss(dscr_out_fake, dscr_fake_labels)\n","                loss.cls_fake = classifier.get_loss(cls_out_fake, fake_labels, is_labeled, n_labeled)\n","                loss.cmp_fake = composite_loss(loss.dscr_fake, loss.cls_fake)\n","\n","                \"\"\"Add the gradients from the fake batch to the real one\"\"\"\n","                loss.cmp_fake.backward()\n","\n","                \"\"\"total loss for discriminator / classifier\"\"\"\n","                loss.cmp = loss.cmp_real + loss.cmp_fake\n","\n","                \"\"\"update discriminator and classifier parameters\"\"\"\n","                discriminator_opt.step()\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                train generator\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                generator.zero_grad()\n","\n","                \"\"\"Since we just updated the discriminator, perform another forward pass of all-fake batch through it\"\"\"\n","                shared_out_gen = shared_net(fake_images)\n","                dscr_out_gen = discriminator(shared_out_gen)\n","                cls_out_gen = classifier(shared_out_gen)\n","\n","                \"\"\"fake labels are real for generator loss\"\"\"\n","                loss.dscr_gen = discriminator.get_loss(dscr_out_gen, dscr_real_labels)\n","                loss.cls_gen = classifier.get_loss(cls_out_gen, real_labels, is_labeled, n_labeled)\n","                loss.cmp_gen = composite_loss(loss.dscr_gen, loss.cls_gen)\n","\n","                loss.cmp_gen.backward()\n","\n","                generator_opt.step()\n","\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                collect train statistics and add to tensorboard log\n","                \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","                total_loss_dict = total_loss.__dict__\n","                for loss_type in loss.__dict__:\n","                    loss_item.__dict__[loss_type] = loss.__dict__[loss_type]\n","                    total_loss_dict[loss_type] += loss_item.__dict__[loss_type]\n","                    writer.add_scalar(f'train_iter_loss/{loss_type}', loss_item.__dict__[loss_type], iter_id)\n","\n","                \"\"\"classification accuracy for real images\"\"\"\n","                _, pred_real = torch.max(cls_out_real.data, 1)\n","                pred_real = pred_real.squeeze()\n","                real_total += real_labels.size(0)\n","                real_correct += pred_real.eq(real_labels).sum().item()\n","\n","                \"\"\"classification accuracy for fake images\"\"\"\n","                _, pred_fake = torch.max(cls_out_fake.data, 1)\n","                pred_fake = pred_fake.squeeze()\n","                fake_total += fake_labels.size(0)\n","                fake_correct += pred_fake.eq(fake_labels).sum().item()\n","\n","                if params.train_gen_metrics:\n","                    \"\"\"resize images to be compatible with inception\"\"\"\n","                    real_images_up = upsample(real_images.detach())\n","                    fake_images_up = upsample(fake_images.detach())\n","\n","                    inception_score = compute_inception_score(fake_images_up, inception_model)\n","                    \"\"\"need only the mean KL Divergence\"\"\"\n","                    inception_score = inception_score[0]\n","                    fid = compute_fid([real_images_up, fake_images_up], fid_model, device=device, dims=params.fid_dims)\n","\n","                    train_inception_score += inception_score\n","                    train_fid += fid\n","\n","                    writer.add_scalar('train_iter/inception_score', inception_score, iter_id)\n","                    writer.add_scalar('train_iter/fid', fid, iter_id)\n","\n","                real_images_grid = make_grid(real_images, padding=2, normalize=True)\n","                fake_images_grid = make_grid(fake_images, padding=2, normalize=True)\n","\n","                writer.add_image('train/real_images', real_images_grid, epoch)\n","                writer.add_image('train/fake_images', fake_images_grid, epoch)\n","\n","                iter_id += 1\n","\n","            for loss_type in loss.__dict__:\n","                mean_loss.__dict__[loss_type] = total_loss.__dict__[loss_type] / (batch_idx + 1)\n","                writer.add_scalar(f'train_loss/{loss_type}', mean_loss.__dict__[loss_type], epoch)\n","                status_df[loss_type]['train'] = mean_loss.__dict__[loss_type]\n","\n","            \"\"\"mean classification accuracy for real, fake and real+fake\"\"\"\n","            real_acc = 100. * real_correct / real_total\n","            fake_acc = 100. * fake_correct / fake_total\n","            total_acc = 100. * (real_correct + fake_correct) / (real_total + fake_total)\n","\n","            if params.train_gen_metrics:\n","                train_inception_score /= (batch_idx + 1)\n","                train_fid /= (batch_idx + 1)\n","                writer.add_scalar('train/fid', train_fid, epoch)\n","                writer.add_scalar('train/inception_score', train_inception_score, epoch)\n","                status_df['is']['train'] = train_inception_score\n","                status_df['fid']['train'] = train_fid\n","\n","            writer.add_scalar('train/total_acc', total_acc, epoch)\n","            writer.add_scalar('train/real_acc', real_acc, epoch)\n","            writer.add_scalar('train/fake_acc', fake_acc, epoch)\n","\n","            status_df['total_acc']['train'] = total_acc\n","            status_df['real_acc']['train'] = real_acc\n","            status_df['fake_acc']['train'] = fake_acc\n","\n","            if epoch % train_params.validate_gap == 0:\n","                valid_loss, valid_acc, valid_gen, valid_time = evaluate(\n","                    all_modules, valid_dataloader, composite_loss, inception_model, fid_model, upsample, device, params)\n","                print('\\nvalidation time: {:.3f}'.format(valid_time))\n","\n","                valid_real_acc, valid_fake_acc, valid_total_acc = valid_acc\n","                valid_inception_score, valid_fid, valid_real_images_grid, valid_fake_images_grid, = valid_gen\n","\n","                for loss_type in loss.__dict__:\n","                    writer.add_scalar(f'valid_loss/{loss_type}', valid_loss.__dict__[loss_type], epoch)\n","                    status_df[loss_type]['valid'] = valid_loss.__dict__[loss_type]\n","\n","                writer.add_image('valid/real_images', valid_real_images_grid, epoch)\n","                writer.add_image('valid/fake_images', valid_fake_images_grid, epoch)\n","\n","                writer.add_scalar('valid/total_acc', valid_total_acc, epoch)\n","                writer.add_scalar('valid/real_acc', valid_real_acc, epoch)\n","                writer.add_scalar('valid/fake_acc', valid_fake_acc, epoch)\n","\n","                if params.eval_gen_metrics:\n","                    writer.add_scalar('valid/fid', valid_fid, epoch)\n","                    writer.add_scalar('valid/inception_score', valid_inception_score, epoch)\n","\n","                    status_df['is']['valid'] = valid_inception_score\n","                    status_df['fid']['valid'] = valid_fid\n","\n","                status_df['total_acc']['valid'] = valid_total_acc\n","                status_df['real_acc']['valid'] = valid_real_acc\n","                status_df['fake_acc']['valid'] = valid_fake_acc\n","            else:\n","                status_df.loc['valid', :] = 0\n","\n","            save_weights, criterion = save_criteria.decide(status_df)\n","\n","            print(\"Training results for epoch: {}:\\n\".format(epoch))\n","            print_stats(status_df)\n","            print()\n","\n","            # Save checkpoint.\n","            if save_weights:\n","                model_dict = {\n","                    'discriminator': discriminator.state_dict(),\n","                    'generator': generator.state_dict(),\n","                    'classifier': classifier.state_dict(),\n","                    'discriminator_opt': discriminator_opt.state_dict(),\n","                    'generator_opt': generator_opt.state_dict(),\n","                    'status_df': status_df,\n","                    'criterion': criterion,\n","                    'epoch': epoch,\n","                    'timestamp': datetime.now().strftime(\"%y/%m/%d %H:%M:%S\"),\n","                }\n","                weights_path = '{}.{:d}'.format(train_params.weights_path, epoch)\n","\n","                print(f'Saving weights for criterion {criterion} to {weights_path}')\n","                torch.save(model_dict, weights_path)\n","\n","    print('Testing...')\n","    test_loss, test_acc, test_gen, test_time = evaluate(\n","        all_modules, test_dataloader, composite_loss, inception_model, fid_model, upsample, device, params)\n","\n","    test_real_acc, test_fake_acc, test_total_acc = test_acc\n","    test_inception_score, test_fid, test_real_images_grid, test_fake_images_grid = test_gen\n","\n","    test_df = pd.DataFrame(\n","        np.zeros((1, len(eval_metrics)), dtype=np.float32),\n","        index=('test',),\n","        columns=eval_metrics,\n","    )\n","    for loss_type in test_loss.__dict__:\n","        test_df[loss_type]['test'] = test_loss.__dict__[loss_type]\n","\n","    test_df['total_acc']['test'] = test_total_acc\n","    test_df['real_acc']['test'] = test_real_acc\n","    test_df['fake_acc']['test'] = test_fake_acc\n","    test_df['is']['test'] = test_inception_score\n","    test_df['fid']['test'] = test_fid\n","\n","    print(\"Test Results:\\n\")\n","    print_stats(test_df)\n","    print()\n","    print('Test Time: {:.3f} sec'.format(test_time))\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":null,"outputs":[]}]}