{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_RNN_version2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Cf3mTwrzooZ_","colab_type":"text"},"source":["#MNIST classification with RNN\n","Treat each row of MNIST image as an input vector at each time point. So, 32 rows will be fed sequentially. After that the output will be probablity vector for classification. This would be an example of a \"sequence-to-vector\" model of RNN "]},{"cell_type":"code","metadata":{"id":"2N2yV-urpZ-W","colab_type":"code","outputId":"acd7f003-cfec-4af2-9730-73550cf05c46","executionInfo":{"status":"ok","timestamp":1572847295148,"user_tz":420,"elapsed":29264,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import torch\n","import torchvision\n","from torch import nn\n","from torch.autograd import Variable\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","n_epochs = 10\n","batch_size_train = 200\n","batch_size_test = 1000\n","\n","random_seed = 1\n","torch.backends.cudnn.enabled = False\n","torch.manual_seed(random_seed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Checking GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BHEVRgmjp66e","colab_type":"code","colab":{}},"source":["from torch.utils.data import random_split\n","\n","MNIST_training = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n","\n","MNIST_test_set = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n","\n","# create a training and a validation set\n","MNIST_training_set, MNIST_validation_set = random_split(MNIST_training, [55000, 5000])\n","\n","train_loader = torch.utils.data.DataLoader(MNIST_training_set,batch_size=batch_size_train, shuffle=True)\n","\n","validation_loader = torch.utils.data.DataLoader(MNIST_validation_set,batch_size=batch_size_train, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(MNIST_test_set,batch_size=batch_size_test, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gFR5bOTqIHY","colab_type":"code","outputId":"1e7397b3-b8cc-4435-964c-9a9dd7437830","executionInfo":{"status":"ok","timestamp":1572847301355,"user_tz":420,"elapsed":579,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)\n","print(example_data.shape,example_targets.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["torch.Size([1000, 1, 28, 28]) torch.Size([1000])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8MKmmX_qQU0","colab_type":"code","colab":{}},"source":["# Source: https://www.dezyre.com/recipes/run-basic-rnn-model-using-pytorch\n","class RNN(nn.Module):\n","    def __init__(self):\n","        super(RNN, self).__init__()\n","\n","        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n","            input_size=28,\n","            hidden_size=64,         # rnn hidden unit\n","            num_layers=1,           # number of rnn layers\n","            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n","        )\n","\n","        self.out = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        # x shape (batch, time_step, input_size)\n","        # r_out shape (batch, time_step, output_size)\n","        # h_n shape (n_layers, batch, hidden_size)\n","        # h_c shape (n_layers, batch, hidden_size)\n","        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n","\n","        # choose r_out at the last time step\n","        out = self.out(r_out[:, -1, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UicfeTI6rCET","colab_type":"code","outputId":"5f06d628-5ce0-46ef-fb71-669f7b9fe34b","executionInfo":{"status":"ok","timestamp":1572847495870,"user_tz":420,"elapsed":188516,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["rnn = RNN().to(device)\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   # optimize all rnn parameters\n","loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n","\n","for epoch in range(10):\n","    for step, (x, y) in enumerate(train_loader):        # gives batch data\n","        b_x = x.view(-1, 28, 28).to(device)             # reshape x to (batch, time_step, input_size)\n","        b_y = y.to(device)                              # batch y\n","\n","        output = rnn(b_x)                               # rnn output\n","        loss = loss_func(output, b_y)                   # cross entropy loss\n","        optimizer.zero_grad()                           # clear gradients for this training step\n","        loss.backward()                                 # backpropagation, compute gradients\n","        optimizer.step()                                # apply gradients\n","\n","        if step % 50 == 0:\n","          with torch.no_grad():\n","            accuracy=0.0\n","            for validation_x, validation_y in validation_loader:\n","              validation_x = validation_x.view(-1, 28, 28).to(device)    # reshape x to (batch, time_step, input_size)\n","              validation_y = validation_y.to(device)                     # batch y\n","              validation_output = rnn(validation_x) \n","              pred = validation_output.data.max(1, keepdim=True)[1]\n","              accuracy += 100.0*pred.eq(validation_y.data.view_as(pred)).sum() / float(len(validation_loader.dataset))\n","            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item(), '| validation accuracy: %.2f' % accuracy)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 2.2986 | validation accuracy: 16.66\n","Epoch:  0 | train loss: 0.5520 | validation accuracy: 82.62\n","Epoch:  0 | train loss: 0.2802 | validation accuracy: 91.70\n","Epoch:  0 | train loss: 0.2289 | validation accuracy: 92.92\n","Epoch:  0 | train loss: 0.2298 | validation accuracy: 93.98\n","Epoch:  0 | train loss: 0.1324 | validation accuracy: 94.96\n","Epoch:  1 | train loss: 0.1832 | validation accuracy: 95.44\n","Epoch:  1 | train loss: 0.1185 | validation accuracy: 96.20\n","Epoch:  1 | train loss: 0.1361 | validation accuracy: 96.54\n","Epoch:  1 | train loss: 0.1390 | validation accuracy: 96.00\n","Epoch:  1 | train loss: 0.1208 | validation accuracy: 96.84\n","Epoch:  1 | train loss: 0.1232 | validation accuracy: 96.24\n","Epoch:  2 | train loss: 0.0598 | validation accuracy: 96.52\n","Epoch:  2 | train loss: 0.1074 | validation accuracy: 96.64\n","Epoch:  2 | train loss: 0.0661 | validation accuracy: 96.72\n","Epoch:  2 | train loss: 0.0444 | validation accuracy: 96.78\n","Epoch:  2 | train loss: 0.0641 | validation accuracy: 97.10\n","Epoch:  2 | train loss: 0.1142 | validation accuracy: 97.10\n","Epoch:  3 | train loss: 0.0454 | validation accuracy: 97.12\n","Epoch:  3 | train loss: 0.1337 | validation accuracy: 97.34\n","Epoch:  3 | train loss: 0.1598 | validation accuracy: 97.34\n","Epoch:  3 | train loss: 0.0542 | validation accuracy: 97.22\n","Epoch:  3 | train loss: 0.0869 | validation accuracy: 97.52\n","Epoch:  3 | train loss: 0.1363 | validation accuracy: 97.28\n","Epoch:  4 | train loss: 0.0624 | validation accuracy: 97.26\n","Epoch:  4 | train loss: 0.0509 | validation accuracy: 97.50\n","Epoch:  4 | train loss: 0.0759 | validation accuracy: 97.12\n","Epoch:  4 | train loss: 0.0445 | validation accuracy: 97.06\n","Epoch:  4 | train loss: 0.1364 | validation accuracy: 97.22\n","Epoch:  4 | train loss: 0.0870 | validation accuracy: 97.30\n","Epoch:  5 | train loss: 0.0799 | validation accuracy: 97.52\n","Epoch:  5 | train loss: 0.1413 | validation accuracy: 97.44\n","Epoch:  5 | train loss: 0.0489 | validation accuracy: 97.54\n","Epoch:  5 | train loss: 0.0112 | validation accuracy: 97.72\n","Epoch:  5 | train loss: 0.0768 | validation accuracy: 97.86\n","Epoch:  5 | train loss: 0.0404 | validation accuracy: 97.42\n","Epoch:  6 | train loss: 0.0819 | validation accuracy: 97.84\n","Epoch:  6 | train loss: 0.0188 | validation accuracy: 97.88\n","Epoch:  6 | train loss: 0.0637 | validation accuracy: 97.54\n","Epoch:  6 | train loss: 0.0343 | validation accuracy: 97.72\n","Epoch:  6 | train loss: 0.0620 | validation accuracy: 97.48\n","Epoch:  6 | train loss: 0.1419 | validation accuracy: 97.10\n","Epoch:  7 | train loss: 0.0282 | validation accuracy: 97.50\n","Epoch:  7 | train loss: 0.0594 | validation accuracy: 97.56\n","Epoch:  7 | train loss: 0.0292 | validation accuracy: 96.86\n","Epoch:  7 | train loss: 0.0889 | validation accuracy: 97.48\n","Epoch:  7 | train loss: 0.0461 | validation accuracy: 97.64\n","Epoch:  7 | train loss: 0.0341 | validation accuracy: 97.30\n","Epoch:  8 | train loss: 0.0559 | validation accuracy: 97.60\n","Epoch:  8 | train loss: 0.0568 | validation accuracy: 97.78\n","Epoch:  8 | train loss: 0.0381 | validation accuracy: 97.98\n","Epoch:  8 | train loss: 0.0708 | validation accuracy: 97.42\n","Epoch:  8 | train loss: 0.0584 | validation accuracy: 97.56\n","Epoch:  8 | train loss: 0.1362 | validation accuracy: 97.42\n","Epoch:  9 | train loss: 0.0719 | validation accuracy: 97.00\n","Epoch:  9 | train loss: 0.0663 | validation accuracy: 97.78\n","Epoch:  9 | train loss: 0.0980 | validation accuracy: 97.24\n","Epoch:  9 | train loss: 0.0365 | validation accuracy: 97.44\n","Epoch:  9 | train loss: 0.1146 | validation accuracy: 97.30\n","Epoch:  9 | train loss: 0.0479 | validation accuracy: 97.60\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C9Dsa_itQkLe","colab_type":"code","outputId":"ca4c5f11-effb-47c9-9bd4-0fca9906a09b","executionInfo":{"status":"ok","timestamp":1572847502477,"user_tz":420,"elapsed":2395,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with torch.no_grad():\n","  accuracy=0.0\n","  for test_x, test_y in test_loader:\n","    test_x = test_x.view(-1, 28, 28).to(device)    # reshape x to (batch, time_step, input_size)\n","    test_y = test_y.to(device)                     # batch y\n","    test_output = rnn(test_x) \n","    pred = test_output.data.max(1, keepdim=True)[1]\n","    accuracy += 100.0*pred.eq(test_y.data.view_as(pred)).sum() / float(len(test_loader.dataset))\n","  print('test accuracy: %.2f' % accuracy)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["test accuracy: 97.78\n"],"name":"stdout"}]}]}