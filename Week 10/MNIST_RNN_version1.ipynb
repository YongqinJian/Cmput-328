{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_RNN_version1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Cf3mTwrzooZ_","colab_type":"text"},"source":["#MNIST classification with RNN\n","Treat each row of MNIST image as an input vector at each time point. So, 32 rows will be fed sequentially. After that the output will be probablity vector for classification. This would be an example of a \"sequence-to-vector\" model of RNN "]},{"cell_type":"code","metadata":{"id":"2N2yV-urpZ-W","colab_type":"code","outputId":"f990838d-ca70-4e97-e5f9-57db80ddb626","executionInfo":{"status":"ok","timestamp":1572843578314,"user_tz":420,"elapsed":941,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import torch\n","import torchvision\n","from torch import nn\n","from torch.autograd import Variable\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","n_epochs = 10\n","batch_size = 200\n","\n","random_seed = 1\n","torch.backends.cudnn.enabled = False\n","torch.manual_seed(random_seed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Checking GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BHEVRgmjp66e","colab_type":"code","colab":{}},"source":["from torch.utils.data import random_split\n","\n","MNIST_training = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n","\n","MNIST_test_set = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n","\n","# create a training and a validation set\n","MNIST_training_set, MNIST_validation_set = random_split(MNIST_training, [55000, 5000])\n","\n","train_loader = torch.utils.data.DataLoader(MNIST_training_set,batch_size=batch_size, shuffle=True)\n","\n","validation_loader = torch.utils.data.DataLoader(MNIST_validation_set,batch_size=batch_size, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(MNIST_test_set,batch_size=batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gFR5bOTqIHY","colab_type":"code","outputId":"61e97cb2-1362-47a2-b2c8-2291f419b61e","executionInfo":{"status":"ok","timestamp":1572843588063,"user_tz":420,"elapsed":949,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)\n","print(example_data.shape,example_targets.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([200, 1, 28, 28]) torch.Size([200])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8MKmmX_qQU0","colab_type":"code","colab":{}},"source":["# One problem \n","class BasicRNN(nn.Module):\n","    def __init__(self, batch_size, n_inputs, n_neurons):\n","        super(BasicRNN, self).__init__()\n","        \n","        self.rnn = nn.LSTMCell(28, 64)                     # input dimension x number of neurons\n","        self.hx = torch.randn(batch_size, 64).to(device)   # initialize hidden state\n","        self.cx = torch.randn(batch_size, 64).to(device)   # initialize memory state\n","        self.out = nn.Linear(64, 10)\n","\n","    def forward(self, X):\n","        # transforms X to dimensions: n_steps X batch_size X n_inputs\n","        X = X.permute(1, 0, 2)\n","\n","        # for each time step - there are 28 rows in the MNIST image\n","        hx = self.hx\n","        cx = self.cx\n","        for i in range(28):\n","            hx, cx = self.rnn(X[i], (hx, cx))\n","        \n","        return self.out(hx)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UicfeTI6rCET","colab_type":"code","outputId":"a15477b2-88d9-45a7-d790-f8095855d2c9","executionInfo":{"status":"ok","timestamp":1572844747295,"user_tz":420,"elapsed":186832,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["rnn = BasicRNN(batch_size,28,64).to(device)\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   # optimize all rnn parameters\n","loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n","\n","for epoch in range(10):\n","    for step, (x, y) in enumerate(train_loader):        # gives batch data\n","        b_x = x.view(-1, 28, 28).to(device)             # reshape x to (batch, time_step, input_size)\n","        b_y = y.to(device)                              # batch y\n","\n","        output = rnn(b_x)                               # rnn output\n","        loss = loss_func(output, b_y)                   # cross entropy loss\n","        optimizer.zero_grad()                           # clear gradients for this training step\n","        loss.backward()                                 # backpropagation, compute gradients\n","        optimizer.step()                                # apply gradients\n","\n","        if step % 50 == 0:\n","          with torch.no_grad():\n","            accuracy=0.0\n","            for validation_x, validation_y in validation_loader:\n","              validation_x = validation_x.view(-1, 28, 28).to(device)    # reshape x to (batch, time_step, input_size)\n","              validation_y = validation_y.to(device)                     # batch y\n","              validation_output = rnn(validation_x) \n","              pred = validation_output.data.max(1, keepdim=True)[1]\n","              accuracy += 100.0*pred.eq(validation_y.data.view_as(pred)).sum() / float(len(validation_loader.dataset))\n","            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item(), '| validation accuracy: %.2f' % accuracy)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 2.3047 | validation accuracy: 10.62\n","Epoch:  0 | train loss: 0.5686 | validation accuracy: 81.62\n","Epoch:  0 | train loss: 0.2626 | validation accuracy: 92.64\n","Epoch:  0 | train loss: 0.2473 | validation accuracy: 92.44\n","Epoch:  0 | train loss: 0.2741 | validation accuracy: 93.62\n","Epoch:  0 | train loss: 0.1467 | validation accuracy: 94.66\n","Epoch:  1 | train loss: 0.1038 | validation accuracy: 95.42\n","Epoch:  1 | train loss: 0.1261 | validation accuracy: 95.90\n","Epoch:  1 | train loss: 0.1259 | validation accuracy: 96.24\n","Epoch:  1 | train loss: 0.1520 | validation accuracy: 95.86\n","Epoch:  1 | train loss: 0.1286 | validation accuracy: 96.10\n","Epoch:  1 | train loss: 0.1419 | validation accuracy: 96.52\n","Epoch:  2 | train loss: 0.0777 | validation accuracy: 96.62\n","Epoch:  2 | train loss: 0.1228 | validation accuracy: 96.80\n","Epoch:  2 | train loss: 0.0834 | validation accuracy: 96.70\n","Epoch:  2 | train loss: 0.1319 | validation accuracy: 96.56\n","Epoch:  2 | train loss: 0.1397 | validation accuracy: 96.68\n","Epoch:  2 | train loss: 0.0838 | validation accuracy: 96.92\n","Epoch:  3 | train loss: 0.0421 | validation accuracy: 96.74\n","Epoch:  3 | train loss: 0.1387 | validation accuracy: 97.40\n","Epoch:  3 | train loss: 0.0391 | validation accuracy: 97.40\n","Epoch:  3 | train loss: 0.0701 | validation accuracy: 96.98\n","Epoch:  3 | train loss: 0.1680 | validation accuracy: 96.66\n","Epoch:  3 | train loss: 0.0190 | validation accuracy: 97.24\n","Epoch:  4 | train loss: 0.0893 | validation accuracy: 96.78\n","Epoch:  4 | train loss: 0.0346 | validation accuracy: 97.50\n","Epoch:  4 | train loss: 0.0870 | validation accuracy: 97.38\n","Epoch:  4 | train loss: 0.0736 | validation accuracy: 97.72\n","Epoch:  4 | train loss: 0.0435 | validation accuracy: 96.82\n","Epoch:  4 | train loss: 0.1061 | validation accuracy: 97.44\n","Epoch:  5 | train loss: 0.0606 | validation accuracy: 97.62\n","Epoch:  5 | train loss: 0.0527 | validation accuracy: 97.04\n","Epoch:  5 | train loss: 0.0831 | validation accuracy: 96.68\n","Epoch:  5 | train loss: 0.1159 | validation accuracy: 97.22\n","Epoch:  5 | train loss: 0.0410 | validation accuracy: 97.68\n","Epoch:  5 | train loss: 0.1205 | validation accuracy: 97.68\n","Epoch:  6 | train loss: 0.0347 | validation accuracy: 97.70\n","Epoch:  6 | train loss: 0.0301 | validation accuracy: 97.58\n","Epoch:  6 | train loss: 0.0331 | validation accuracy: 97.42\n","Epoch:  6 | train loss: 0.0617 | validation accuracy: 97.18\n","Epoch:  6 | train loss: 0.0596 | validation accuracy: 97.36\n","Epoch:  6 | train loss: 0.1820 | validation accuracy: 97.38\n","Epoch:  7 | train loss: 0.1033 | validation accuracy: 97.20\n","Epoch:  7 | train loss: 0.0947 | validation accuracy: 97.24\n","Epoch:  7 | train loss: 0.0688 | validation accuracy: 97.22\n","Epoch:  7 | train loss: 0.0367 | validation accuracy: 97.52\n","Epoch:  7 | train loss: 0.0994 | validation accuracy: 97.26\n","Epoch:  7 | train loss: 0.0664 | validation accuracy: 97.28\n","Epoch:  8 | train loss: 0.0191 | validation accuracy: 97.18\n","Epoch:  8 | train loss: 0.0508 | validation accuracy: 97.24\n","Epoch:  8 | train loss: 0.0820 | validation accuracy: 96.90\n","Epoch:  8 | train loss: 0.0407 | validation accuracy: 96.96\n","Epoch:  8 | train loss: 0.0933 | validation accuracy: 97.50\n","Epoch:  8 | train loss: 0.0370 | validation accuracy: 97.08\n","Epoch:  9 | train loss: 0.0497 | validation accuracy: 97.62\n","Epoch:  9 | train loss: 0.0474 | validation accuracy: 97.64\n","Epoch:  9 | train loss: 0.0543 | validation accuracy: 97.04\n","Epoch:  9 | train loss: 0.0469 | validation accuracy: 97.32\n","Epoch:  9 | train loss: 0.0924 | validation accuracy: 97.14\n","Epoch:  9 | train loss: 0.0507 | validation accuracy: 97.66\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C9Dsa_itQkLe","colab_type":"code","outputId":"e8c0ea12-c9da-4512-fa53-31c9aae8d396","executionInfo":{"status":"ok","timestamp":1572845508329,"user_tz":420,"elapsed":2859,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with torch.no_grad():\n","  accuracy=0.0\n","  for test_x, test_y in test_loader:\n","    test_x = test_x.view(-1, 28, 28).to(device)    # reshape x to (batch, time_step, input_size)\n","    test_y = test_y.to(device)                     # batch y\n","    test_output = rnn(test_x) \n","    pred = test_output.data.max(1, keepdim=True)[1]\n","    accuracy += 100.0*pred.eq(test_y.data.view_as(pred)).sum() / float(len(test_loader.dataset))\n","  print('test accuracy: %.2f' % accuracy)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["test accuracy: 97.38\n"],"name":"stdout"}]}]}