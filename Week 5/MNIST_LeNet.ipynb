{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4BNOnZe46CQ",
        "colab_type": "code",
        "outputId": "73f0cbb6-df7f-4624-b7b7-c0d556c60409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size_train = 200\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 100\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Checking GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2uiYpfC4_aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "MNIST_training = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.Pad(padding=2),\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "\n",
        "MNIST_test_set = torchvision.datasets.MNIST('/content/drive/My Drive/HIP2019/MNIST_dataset/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.Pad(padding=2),\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "\n",
        "# create a training and a validation set\n",
        "MNIST_training_set, MNIST_validation_set = random_split(MNIST_training, [55000, 5000])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(MNIST_training_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(MNIST_validation_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(MNIST_test_set,batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSq8BOG85GyN",
        "colab_type": "code",
        "outputId": "593c39c1-f2b1-4421-dcf1-ddab7d0b1078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "print(example_data.shape)\n",
        "print(example_targets.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 32, 32])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1hgLmOT5KsW",
        "colab_type": "code",
        "outputId": "42a89f31-e7d7-4d4d-bcc4-cfae24d16f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSefejI4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSefejI4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM32G_zp52dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1MU6Yh56HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kvJi8g6Fpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "validation_losses = []\n",
        "validation_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy8SKSrG6KxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "      torch.save(network.state_dict(), '/content/drive/My Drive/HIP2019/MNIST_LeNet_results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/drive/My Drive/HIP2019/MNIST_LeNet_results/optimizer.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr4Bd0BI6P7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation():\n",
        "  network.eval()\n",
        "  validation_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in validation_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = network(data)\n",
        "      validation_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  validation_loss /= len(validation_loader.dataset)\n",
        "  validation_losses.append(validation_loss)\n",
        "  print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    validation_loss, correct, len(validation_loader.dataset),\n",
        "    100. * correct / len(validation_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi7288T3U8Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRG7c7Sy6XOs",
        "colab_type": "code",
        "outputId": "3ce17c18-559c-476e-c9b7-420eb4b2cf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "network = Net().to(device)\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)\n",
        "\n",
        "validation()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  validation()\n",
        "test()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Avg. loss: 2.3063, Accuracy: 406/5000 (8%)\n",
            "\n",
            "Train Epoch: 1 [0/55000 (0%)]\tLoss: 2.304815\n",
            "Train Epoch: 1 [20000/55000 (36%)]\tLoss: 2.290259\n",
            "Train Epoch: 1 [40000/55000 (73%)]\tLoss: 2.268971\n",
            "\n",
            "Validation set: Avg. loss: 2.1913, Accuracy: 2711/5000 (54%)\n",
            "\n",
            "Train Epoch: 2 [0/55000 (0%)]\tLoss: 2.188427\n",
            "Train Epoch: 2 [20000/55000 (36%)]\tLoss: 0.677236\n",
            "Train Epoch: 2 [40000/55000 (73%)]\tLoss: 0.327342\n",
            "\n",
            "Validation set: Avg. loss: 0.3278, Accuracy: 4501/5000 (90%)\n",
            "\n",
            "Train Epoch: 3 [0/55000 (0%)]\tLoss: 0.280150\n",
            "Train Epoch: 3 [20000/55000 (36%)]\tLoss: 0.174515\n",
            "Train Epoch: 3 [40000/55000 (73%)]\tLoss: 0.237195\n",
            "\n",
            "Validation set: Avg. loss: 0.1893, Accuracy: 4693/5000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/55000 (0%)]\tLoss: 0.137607\n",
            "Train Epoch: 4 [20000/55000 (36%)]\tLoss: 0.153521\n",
            "Train Epoch: 4 [40000/55000 (73%)]\tLoss: 0.223039\n",
            "\n",
            "Validation set: Avg. loss: 0.1491, Accuracy: 4776/5000 (95%)\n",
            "\n",
            "Train Epoch: 5 [0/55000 (0%)]\tLoss: 0.092557\n",
            "Train Epoch: 5 [20000/55000 (36%)]\tLoss: 0.211306\n",
            "Train Epoch: 5 [40000/55000 (73%)]\tLoss: 0.095439\n",
            "\n",
            "Validation set: Avg. loss: 0.1371, Accuracy: 4780/5000 (95%)\n",
            "\n",
            "Train Epoch: 6 [0/55000 (0%)]\tLoss: 0.203248\n",
            "Train Epoch: 6 [20000/55000 (36%)]\tLoss: 0.077058\n",
            "Train Epoch: 6 [40000/55000 (73%)]\tLoss: 0.160598\n",
            "\n",
            "Validation set: Avg. loss: 0.1075, Accuracy: 4823/5000 (96%)\n",
            "\n",
            "Train Epoch: 7 [0/55000 (0%)]\tLoss: 0.145520\n",
            "Train Epoch: 7 [20000/55000 (36%)]\tLoss: 0.055076\n",
            "Train Epoch: 7 [40000/55000 (73%)]\tLoss: 0.152964\n",
            "\n",
            "Validation set: Avg. loss: 0.1025, Accuracy: 4843/5000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/55000 (0%)]\tLoss: 0.098603\n",
            "Train Epoch: 8 [20000/55000 (36%)]\tLoss: 0.133049\n",
            "Train Epoch: 8 [40000/55000 (73%)]\tLoss: 0.167449\n",
            "\n",
            "Validation set: Avg. loss: 0.0846, Accuracy: 4855/5000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/55000 (0%)]\tLoss: 0.078468\n",
            "Train Epoch: 9 [20000/55000 (36%)]\tLoss: 0.090625\n",
            "Train Epoch: 9 [40000/55000 (73%)]\tLoss: 0.071398\n",
            "\n",
            "Validation set: Avg. loss: 0.0862, Accuracy: 4859/5000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/55000 (0%)]\tLoss: 0.064281\n",
            "Train Epoch: 10 [20000/55000 (36%)]\tLoss: 0.089024\n",
            "Train Epoch: 10 [40000/55000 (73%)]\tLoss: 0.089648\n",
            "\n",
            "Validation set: Avg. loss: 0.0809, Accuracy: 4861/5000 (97%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 0.0654, Accuracy: 9780/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oqzdCF2o-d2",
        "colab_type": "code",
        "outputId": "0ca446a3-95b0-4a43-a25e-90a4cd77b607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# load a saved model and evaluate on test set\n",
        "\n",
        "\n",
        "network = Net().to(device)\n",
        "\n",
        "network.load_state_dict(torch.load('/content/drive/My Drive/HIP2019/MNIST_LeNet_results/model.pth'))\n",
        "\n",
        "test()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.0420, Accuracy: 9848/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFrrW_QtrI3l",
        "colab_type": "code",
        "outputId": "5ad30d6a-26b4-43ef-d583-1b982e7a928d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load a model and resume training\n",
        "\n",
        "network = Net().to(device)\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)\n",
        "\n",
        "network.load_state_dict(torch.load('/content/drive/My Drive/HIP2019/MNIST_LeNet_results/model.pth'))\n",
        "optimizer.load_state_dict(torch.load('/content/drive/My Drive/HIP2019/MNIST_LeNet_results/optimizer.pth'))\n",
        "\n",
        "validation()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  validation()\n",
        "test()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Avg. loss: 0.0534, Accuracy: 4913/5000 (98%)\n",
            "\n",
            "Train Epoch: 1 [0/55000 (0%)]\tLoss: 0.059633\n",
            "Train Epoch: 1 [12800/55000 (23%)]\tLoss: 0.024473\n",
            "Train Epoch: 1 [25600/55000 (47%)]\tLoss: 0.091762\n",
            "Train Epoch: 1 [38400/55000 (70%)]\tLoss: 0.048940\n",
            "Train Epoch: 1 [51200/55000 (93%)]\tLoss: 0.073472\n",
            "\n",
            "Validation set: Avg. loss: 0.0545, Accuracy: 4919/5000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/55000 (0%)]\tLoss: 0.050171\n",
            "Train Epoch: 2 [12800/55000 (23%)]\tLoss: 0.053173\n",
            "Train Epoch: 2 [25600/55000 (47%)]\tLoss: 0.014093\n",
            "Train Epoch: 2 [38400/55000 (70%)]\tLoss: 0.049234\n",
            "Train Epoch: 2 [51200/55000 (93%)]\tLoss: 0.034479\n",
            "\n",
            "Validation set: Avg. loss: 0.0557, Accuracy: 4907/5000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/55000 (0%)]\tLoss: 0.037109\n",
            "Train Epoch: 3 [12800/55000 (23%)]\tLoss: 0.014686\n",
            "Train Epoch: 3 [25600/55000 (47%)]\tLoss: 0.075705\n",
            "Train Epoch: 3 [38400/55000 (70%)]\tLoss: 0.024813\n",
            "Train Epoch: 3 [51200/55000 (93%)]\tLoss: 0.059719\n",
            "\n",
            "Validation set: Avg. loss: 0.0504, Accuracy: 4922/5000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/55000 (0%)]\tLoss: 0.010582\n",
            "Train Epoch: 4 [12800/55000 (23%)]\tLoss: 0.012016\n",
            "Train Epoch: 4 [25600/55000 (47%)]\tLoss: 0.053490\n",
            "Train Epoch: 4 [38400/55000 (70%)]\tLoss: 0.043909\n",
            "Train Epoch: 4 [51200/55000 (93%)]\tLoss: 0.023047\n",
            "\n",
            "Validation set: Avg. loss: 0.0475, Accuracy: 4927/5000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/55000 (0%)]\tLoss: 0.053286\n",
            "Train Epoch: 5 [12800/55000 (23%)]\tLoss: 0.014147\n",
            "Train Epoch: 5 [25600/55000 (47%)]\tLoss: 0.023490\n",
            "Train Epoch: 5 [38400/55000 (70%)]\tLoss: 0.030747\n",
            "Train Epoch: 5 [51200/55000 (93%)]\tLoss: 0.012758\n",
            "\n",
            "Validation set: Avg. loss: 0.0472, Accuracy: 4930/5000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/55000 (0%)]\tLoss: 0.010763\n",
            "Train Epoch: 6 [12800/55000 (23%)]\tLoss: 0.050196\n",
            "Train Epoch: 6 [25600/55000 (47%)]\tLoss: 0.020125\n",
            "Train Epoch: 6 [38400/55000 (70%)]\tLoss: 0.019365\n",
            "Train Epoch: 6 [51200/55000 (93%)]\tLoss: 0.055575\n",
            "\n",
            "Validation set: Avg. loss: 0.0493, Accuracy: 4922/5000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/55000 (0%)]\tLoss: 0.052458\n",
            "Train Epoch: 7 [12800/55000 (23%)]\tLoss: 0.040497\n",
            "Train Epoch: 7 [25600/55000 (47%)]\tLoss: 0.026543\n",
            "Train Epoch: 7 [38400/55000 (70%)]\tLoss: 0.035028\n",
            "Train Epoch: 7 [51200/55000 (93%)]\tLoss: 0.037114\n",
            "\n",
            "Validation set: Avg. loss: 0.0435, Accuracy: 4940/5000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/55000 (0%)]\tLoss: 0.017651\n",
            "Train Epoch: 8 [12800/55000 (23%)]\tLoss: 0.021958\n",
            "Train Epoch: 8 [25600/55000 (47%)]\tLoss: 0.026895\n",
            "Train Epoch: 8 [38400/55000 (70%)]\tLoss: 0.026088\n",
            "Train Epoch: 8 [51200/55000 (93%)]\tLoss: 0.025452\n",
            "\n",
            "Validation set: Avg. loss: 0.0420, Accuracy: 4939/5000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/55000 (0%)]\tLoss: 0.068423\n",
            "Train Epoch: 9 [12800/55000 (23%)]\tLoss: 0.012059\n",
            "Train Epoch: 9 [25600/55000 (47%)]\tLoss: 0.015190\n",
            "Train Epoch: 9 [38400/55000 (70%)]\tLoss: 0.010526\n",
            "Train Epoch: 9 [51200/55000 (93%)]\tLoss: 0.021317\n",
            "\n",
            "Validation set: Avg. loss: 0.0464, Accuracy: 4927/5000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/55000 (0%)]\tLoss: 0.075792\n",
            "Train Epoch: 10 [12800/55000 (23%)]\tLoss: 0.052231\n",
            "Train Epoch: 10 [25600/55000 (47%)]\tLoss: 0.120166\n",
            "Train Epoch: 10 [38400/55000 (70%)]\tLoss: 0.004326\n",
            "Train Epoch: 10 [51200/55000 (93%)]\tLoss: 0.012211\n",
            "\n",
            "Validation set: Avg. loss: 0.0442, Accuracy: 4929/5000 (98%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 0.0347, Accuracy: 9880/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}