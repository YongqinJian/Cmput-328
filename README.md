# Cmput-328 Visual Recognition



[Instructor's Webpage](https://webdocs.cs.ualberta.ca/~nray1/)

Email Address: nray1@cs.ualberta.ca

## Syllabus

### Introduction

The goal of the course is to make students familiar with a fascinating application area of machine learning: visual recognition. In visual recognition, a machine attempts to understand scenes or world from visual cues, i.e., images and videos. The application is widespread nowadays with the availability of cameras everywhere. Successful commercial systems based on visual recognition range from entertainment to serious scientific research: face detection and recognition on personal devices, social media, etc., Kinect gaming, robot navigation on Mars, cancer research, and so on. CMPUT 328 will emphasize on the use of the deep convolutional neural network for visual recognition.

### Prerequisites

Math 114 and Math 125 for the understanding of basic continuous math and basic linear algebra.

Stat 141 and Stat 151 or Stat 235 for a basic understanding of probability and statistics

CMPUT 115 or CMPUT 175 for knowing programming basics.

Familiarity with Python will be required. If you don't meet the above requirements exactly, but you have taken similar courses, seek permission from the instructor to enroll.

### Learning outcome

At the end of the course, the students will know the basic principles behind visual recognition: how a computer learns to recognize objects from images and videos. The students will also learn to build visual recognition systems using freely available python-based toolboxes, such as PyTorch.

### Course content

1. Introduction to visual recognition

2. Introduction to Images and videos

3. Hand engineered features and visual recognition.

4. Introduction to convnet

5. Backpropagation and training of convnet

6. Image classification with convnet

7. Object localization with convnet

8. Semantic segmentation with convnet

9. Autoencoders

10. Recurrent neural network

### Instructional method

One three-hour lecture per week will cover instructions and some hands-on practices. Students are required to use their laptops/desktops for the lecture with the required software and tools (see course materials below). Internet connections will be required for the lectures. Part of the lecture will be posted by pre-recorded videos and other parts will be delivered synchronously in the online lecture. Some hands-on practice will be there.

There are no formal labs to attend. TAs will post pre-recorded videos to explain lab assignments. Students are encouraged to post their questions in the discussion forum. Students will also be able to meet the TAs online. Details for the meeting process will be posted later.

### Course materials

1. Textbook: There is no assigned textbook for this course. **A good reference is http://cs231n.stanford.edu/syllabus.html.** The instructor will post relevant course materials in eClass.

2.Required software and tools: Students will need to bring their own laptops to the class. PyTorch and python-based tools will be used in the Google colaboratory.

### Assignments and evaluation

1.Six assignments (Total 60% weight) based on course materials will be given. These individual student assignments will be programming tasks using PyTorch. Two-thirds of the weight for an assignment will be allocated for the accuracy and/or efficiency for the code. The rest one-third weight will be allocated for the documentation of the code where you will explain the logic/algorithm. A sample well-docomented code will be posted.

Late policy for assignments: each student will get a total of 4 late days for the whole course that they can spend on the assignments according to their needs. Once these late days are used up, any submission after the due date will not be accepted.

2.Quizzes (Total 10% weight) will focus on the lecture materials covered. The number of quizzes and dates for the quizzes will be posted soon.

3.The final exam (Total 30% weight) will emphasize on theoretical aspects, such as gradient descent, back-propagation, and so on. date: December 2, time to be decided. It will be an open book and an open internet course. We may be using Smart Exam Monitor for the final exam.
