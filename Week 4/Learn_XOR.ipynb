{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Learn_XOR.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"B6Zcl1xDtKY3","colab_type":"code","colab":{}},"source":["# This notebook implements a neural net to apprximate XOR function using PyTorch\n","from __future__ import print_function\n","import numpy as np\n","import torch\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfA-FfFG1792","colab_type":"code","outputId":"a412e635-f39d-4495-a574-e5a0d01fba46","executionInfo":{"status":"ok","timestamp":1562991254444,"user_tz":360,"elapsed":1564,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["X = torch.tensor([[1.0,0.0,0.0,1.0],[0.0,0.0,1.0,1.0]],dtype=torch.float32) # 2x4 matrix\n","X = torch.transpose(X,0,1)\n","Y = torch.tensor([[1.0,0.0,1.0,0.0]],dtype=torch.float32)                   # 1x4 vector\n","Y = torch.transpose(Y,0,1)\n","print(\"input: \", X)\n","print(\"output: \", Y)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["input:  tensor([[1., 0.],\n","        [0., 0.],\n","        [0., 1.],\n","        [1., 1.]])\n","output:  tensor([[1.],\n","        [0.],\n","        [1.],\n","        [0.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gHOSWcDL1_vh","colab_type":"code","outputId":"4f279a0c-1af4-4e19-f9bb-bf4d6d8bf65b","executionInfo":{"status":"ok","timestamp":1562991489203,"user_tz":360,"elapsed":4630,"user":{"displayName":"Nilanjan Ray","photoUrl":"","userId":"13266317426275772701"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# parameters of neural net\n","W1 = Variable(torch.torch.FloatTensor(2, 8).uniform_(-1, 1), requires_grad=True) # 2x8 matrix\n","b1 = Variable(torch.zeros((1,8)), requires_grad=True)                            # 1x8 matrix\n","W2 = Variable(torch.torch.FloatTensor(8, 1).uniform_(-1, 1), requires_grad=True) # 8x1 matrix\n","b2 = Variable(torch.zeros([1]), requires_grad=True)                              # scalar\n","\n","learning_rate = 0.05\n","optimizer = torch.optim.SGD([W1, b1, W2, b2], lr=learning_rate, momentum=0.9)    # Torch optimizer\n","\n","loss_fn = torch.nn.MSELoss() # Eclidean loss function\n","\n","for step in range(10000):\n","\n","  # forward pass\n","  Z1 = torch.mm(X,W1)    # 4x8 matrix\n","  Z2 = Z1 + b1           # 4x8 matrix\n","  Z3 = torch.sigmoid(Z2) # 4x8 matrix\n","  Z4 = torch.mm(Z3,W2)   # 4x1 vector\n","  Z5 = Z4 + b2           # 4x1 vector\n","  Yp = torch.sigmoid(Z5) # 4x1 vector\n","\n","  # backward pass\n","  optimizer.zero_grad()  # zero out previous gradients\n","  loss = loss_fn(Yp,Y)   # compute loss\n","  loss.backward()        # calculate gradients\n","  #Yp.backward(Yp-Y)     # or, apply gradient of loss at Yp!\n","  #Z5.backward(Yp*(1.0-Yp)*(Yp-Y)) # or, apply gradient of Yp at Z5!\n","  optimizer.step()       # apply new gradients\n","\n","  if step%1000 == 0: \n","    print(\"loss:\",loss.item())\n","\n","print(Yp)\n","print(Y)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["loss: 0.27758413553237915\n","loss: 0.16061058640480042\n","loss: 0.013525567017495632\n","loss: 0.0043778009712696075\n","loss: 0.0023933614138513803\n","loss: 0.0015954060945659876\n","loss: 0.001177772879600525\n","loss: 0.0009248615824617445\n","loss: 0.0007568346336483955\n","loss: 0.0006378335529007018\n","tensor([[0.9759],\n","        [0.0207],\n","        [0.9786],\n","        [0.0270]], grad_fn=<SigmoidBackward>)\n","tensor([[1.],\n","        [0.],\n","        [1.],\n","        [0.]])\n"],"name":"stdout"}]}]}